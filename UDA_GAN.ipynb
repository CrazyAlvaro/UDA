{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "UOmUNvGYgPRN",
      "metadata": {
        "id": "UOmUNvGYgPRN"
      },
      "source": [
        "# Unsupervised Domain Adaptation Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ExU_wmMAgVsR",
      "metadata": {
        "id": "ExU_wmMAgVsR"
      },
      "source": [
        "## 1: Data download\n",
        "Load data to project from Google Drive. Copy a subset of classes of images to the path:\n",
        "- `adaptiope_small/product_images`\n",
        "- `adaptiope_small/real_life` \n",
        "\n",
        "two directories. They represent images from two different domain **product** and **real_life**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4134f6cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4134f6cf",
        "outputId": "3495f32c-69b7-4cea-8004-ba0a1bfda09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from os import makedirs, listdir\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "from shutil import copytree\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!mkdir dataset\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/data/Adaptiope.zip\" dataset/\n",
        "# !ls dataset\n",
        "\n",
        "!unzip -qq dataset/Adaptiope.zip   # unzip file\n",
        "\n",
        "!rm -rf dataset/Adaptiope.zip \n",
        "!rm -rf adaptiope_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0a6cac67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a6cac67",
        "outputId": "e3011c24-7efe-411b-be93-9e6d3170e8fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hoverboard', 'wristwatch', 'stethoscope', 'knife', 'screwdriver', 'desk lamp', 'game controller', 'purse', 'ruler', 'bookcase', 'grill', 'telescope', 'fighter jet', 'keyboard', 'magic lamp', 'shower head', 'coat hanger', 'network switch', 'microwave', 'axe', 'rubber boat', 'boxing gloves', 'toothbrush', 'bicycle helmet', 'acoustic guitar', 'stroller', 'scissors', 'skateboard', 'tape dispenser', 'hard-wired fixed phone', 'in-ear headphones', 'ice cube tray', 'letter tray', 'tank', 'chainsaw', 'electric shaver', 'cellphone', 'vr goggles', 'tent', 'stand mixer', 'handgun', 'fan', 'corkscrew', 'power drill', 'stapler', 'power strip', 'puncher', 'scooter', 'usb stick', 'speakers', 'printer', 'crown', 'laptop', 'sewing machine', 'backpack', 'vacuum cleaner', 'smoking pipe', 'bicycle', 'pikachu', 'binoculars', 'lawn mower', 'calculator', 'watering can', 'glasses', 'drum set', 'nail clipper', 'wallet', 'baseball bat', 'monitor', 'rifle', 'fire extinguisher', 'spatula', 'snow shovel', 'over-ear headphones', 'trash can', 'notepad', 'dart', 'mug', 'electric guitar', 'computer', 'bottle', 'pipe wrench', 'hot glue gun', 'skeleton', 'motorbike helmet', 'computer mouse', 'roller skates', 'pen', 'wheelchair', 'flat iron', 'pogo stick', 'webcam', 'projector', 'hand mixer', 'cordless fixed phone', 'razor', 'office chair', 'toilet brush', 'hair dryer', 'ice skates', 'diving fins', 'mixing console', 'compass', 'phonograph', 'sword', 'file cabinet', 'rc car', 'umbrella', 'hourglass', 'ring binder', 'tyrannosaurus', 'syringe', 'ladder', 'brachiosaurus', 'smartphone', 'comb', 'car jack', 'hat', 'golf club', 'quadcopter', 'handcuffs', 'sleeping bag', 'helicopter']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 20.16it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 27.28it/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir adaptiope_small\n",
        "classes = listdir(\"Adaptiope/product_images\")\n",
        "print(classes)\n",
        "classes = [\"backpack\", \"bookcase\", \"car jack\", \"comb\", \"crown\", \"file cabinet\", \"flat iron\", \"game controller\", \"glasses\",\n",
        "           \"helicopter\", \"ice skates\", \"letter tray\", \"monitor\", \"mug\", \"network switch\", \"over-ear headphones\", \"pen\",\n",
        "           \"purse\", \"stand mixer\", \"stroller\"]\n",
        "domain_classes = [\"product_images\", \"real_life\"]\n",
        "for d, td in zip([\"Adaptiope/product_images\", \"Adaptiope/real_life\"], [\"adaptiope_small/product_images\", \"adaptiope_small/real_life\"]):\n",
        "  makedirs(td)\n",
        "  for c in tqdm(classes):\n",
        "    c_path = join(d, c)\n",
        "    c_target = join(td, c)\n",
        "    copytree(c_path, c_target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_path = 'adaptiope_small/product_images'\n",
        "real_life_path = 'adaptiope_small/real_life'"
      ],
      "metadata": {
        "id": "S8yOthKskBmC"
      },
      "id": "S8yOthKskBmC",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "uUHNozN6ggRr",
      "metadata": {
        "id": "uUHNozN6ggRr"
      },
      "source": [
        "## 2: Domain-Adversarial training of Neural Network\n",
        "We implement DANN UDA method [DANN](https://arxiv.org/pdf/1505.07818.pdf)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fwiJOBXWpeS0",
      "metadata": {
        "id": "fwiJOBXWpeS0"
      },
      "source": [
        "### 2.0: Import Libraries and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "_GZxbLlT6O8m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GZxbLlT6O8m",
        "outputId": "f1d11fdc-d0f3-40dc-a576-af21f66f540e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size:  (679, 679)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from os.path import join\n",
        "import math\n",
        "\n",
        "img = Image.open(join(product_path, 'backpack', 'backpack_003.jpg'))\n",
        "print('Image size: ', img.size)\n",
        "#img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RE2WUwy9BORV",
      "metadata": {
        "id": "RE2WUwy9BORV"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Vei6SzEeggzU",
      "metadata": {
        "id": "Vei6SzEeggzU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import softmax\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import vgg11, alexnet \n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M5rt9x7nBKiT",
      "metadata": {
        "id": "M5rt9x7nBKiT"
      },
      "source": [
        "configuration constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "JXznFSNkAzn3",
      "metadata": {
        "id": "JXznFSNkAzn3"
      },
      "outputs": [],
      "source": [
        "img_size = 256\n",
        "# mean, std used by pre-trained models from PyTorch\n",
        "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "config = dict(epochs=10, batch_size=64,lr=0.01, wd=0.001, momentum=0.9, alpha=10, beta=0.75, gamma=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Rz4CI9spEkN",
      "metadata": {
        "id": "_Rz4CI9spEkN"
      },
      "source": [
        "Configue GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "nHv2o65FpDpn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHv2o65FpDpn",
        "outputId": "90c8eb11-5ca7-4830-d228-42e38c0a158a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "GF3YyTBAhJk8",
      "metadata": {
        "id": "GF3YyTBAhJk8"
      },
      "outputs": [],
      "source": [
        "def get_dataset(root_path):\n",
        "  '''\n",
        "    Get dataset from specific data path\n",
        "\n",
        "    # parameters:\n",
        "        root_path: path to image folder\n",
        "\n",
        "    # return: train_loader, test_loader\n",
        "  '''\n",
        "  # Construct image transform\n",
        "  image_transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.CenterCrop(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "  ])\n",
        "\n",
        "  # Load data from filesystem\n",
        "  image_dataset = ImageFolder(root_path, transform=image_transform)\n",
        "\n",
        "  return image_dataset\n",
        "\n",
        "def get_dataloader(dataset, batch_size, shuffle_train=True, shuffle_test=False):\n",
        "  '''\n",
        "    Get DataLoader from specific data path\n",
        "\n",
        "    # parameters:\n",
        "        dataset: ImageFolder instance\n",
        "        batch_size: batch_size for DataLoader\n",
        "        shuffle_train: whether to shuffle training data\n",
        "        shuffle_test: whether to shuffle test data\n",
        "  '''\n",
        "  # Get train, test number\n",
        "  num_total = len(dataset)\n",
        "  num_train = int(num_total * 0.8 + 1)\n",
        "  num_test  = num_total - num_train\n",
        "\n",
        "  # random split dataset\n",
        "  data_train, data_test = random_split(dataset, [num_train, num_test])\n",
        "\n",
        "  # initialize dataloaders\n",
        "  loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=shuffle_train)\n",
        "  loader_test  = DataLoader(data_test, batch_size=batch_size, shuffle=shuffle_test)\n",
        "\n",
        "  return loader_train, loader_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-J4MSc3spcYU",
      "metadata": {
        "id": "-J4MSc3spcYU"
      },
      "source": [
        "### 2.1 Define Feature Extractor with Pretrain Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "95ff2db4",
      "metadata": {
        "id": "95ff2db4"
      },
      "outputs": [],
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "\n",
        "    # Feature Extractor with AlexNet\n",
        "    self.feature_extractor = alexnet(weights='DEFAULT')\n",
        "    self.feature_dim = self.feature_extractor.classifier[-1].in_features\n",
        "\n",
        "    # make the last layer identity\n",
        "    self.feature_extractor.classifier[-1] = nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.feature_extractor(x)\n",
        "  \n",
        "  def output_dim(self):\n",
        "    return self.feature_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZjWy3ak98L0F",
      "metadata": {
        "id": "ZjWy3ak98L0F"
      },
      "source": [
        "### 2.2 Define Classifier, Discriminator with RevereLayerF for training the Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "517118c3",
      "metadata": {
        "id": "517118c3"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.activation import Softmax\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, output_dim),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.classifier(X) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "RES6EY4PO7KF",
      "metadata": {
        "id": "RES6EY4PO7KF"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Function\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, tensor):\n",
        "        return tensor.view_as(tensor)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg(), None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "K9syaPhFxOFd",
      "metadata": {
        "id": "K9syaPhFxOFd"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.discriminator =  nn.Sequential(\n",
        "            nn.Linear(int(input_dim), 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024,1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        validity = self.discriminator(x)\n",
        "        return validity "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "BsbwoZkZwjjl",
      "metadata": {
        "id": "BsbwoZkZwjjl"
      },
      "outputs": [],
      "source": [
        "class DANN(nn.Module):\n",
        "  # def __init__(self, num_classes, adversarial=True):\n",
        "  def __init__(self, num_classes):\n",
        "    super(DANN, self).__init__()\n",
        "    self.output_dim = num_classes\n",
        "\n",
        "    # define inner network component\n",
        "    self.feature_extractor = FeatureExtractor()\n",
        "    self.classifier = Classifier(self.feature_extractor.output_dim(), num_classes)\n",
        "    self.discriminator = Discriminator(self.feature_extractor.output_dim())  \n",
        "  \n",
        "  def forward(self, x):\n",
        "    feature_output = self.feature_extractor(x)\n",
        "\n",
        "    class_pred = self.classifier(feature_output)\n",
        "\n",
        "    # Add a ReverseLayer here for negative gradient computation\n",
        "    reverse_feature = ReverseLayerF.apply(feature_output)\n",
        "    domain_pred = self.discriminator(reverse_feature)\n",
        "\n",
        "    return class_pred, domain_pred "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IhnsX7lq5saz",
      "metadata": {
        "id": "IhnsX7lq5saz"
      },
      "source": [
        "### 2.3 Cost function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "q6BkiCH_5sOr",
      "metadata": {
        "id": "q6BkiCH_5sOr"
      },
      "outputs": [],
      "source": [
        "def get_class_loss_func():\n",
        "  return nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B-y0dTPj5zrR",
      "metadata": {
        "id": "B-y0dTPj5zrR"
      },
      "source": [
        "### 2.4 Optimizer\n",
        "\n",
        "Setting the **learning rate** according to the original [paper](https://arxiv.org/pdf/1505.07818.pdf) section 5.2.2\n",
        "\n",
        "$$ \\mu_p =  \\frac{\\mu_0}{(1+\\alpha \\cdot p)^\\beta}$$\n",
        "\n",
        "where p is the training progress linearly changing from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "ZsoNnQCq2aEt",
      "metadata": {
        "id": "ZsoNnQCq2aEt"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, config, progress, adversarial=True):\n",
        "  '''\n",
        "  Config Optimizer\n",
        "  '''\n",
        "  learning_rate = config['lr']\n",
        "  learning_rate = learning_rate / ((1 + config['alpha']*progress)**config['beta'])\n",
        "\n",
        "  weight_decay  = config['wd']\n",
        "  momentum      = config['momentum']\n",
        "\n",
        "  feature_ext   = model.get_submodule(\"feature_extractor\")\n",
        "  classifier    = model.get_submodule(\"classifier\")\n",
        "  discriminator = model.get_submodule(\"discriminator\")\n",
        "\n",
        "  pre_trained_weights = feature_ext.parameters()\n",
        "\n",
        "  if adversarial:\n",
        "    other_weights = list(classifier.parameters()) + list(discriminator.parameters())\n",
        "  else:\n",
        "    other_weights = list(classifier.parameters())\n",
        "\n",
        "  # assign parameters to parameters\n",
        "  optimizer = torch.optim.SGD([\n",
        "    {'params': pre_trained_weights},\n",
        "    {'params': other_weights, 'lr': learning_rate}\n",
        "  ], lr= learning_rate/10, weight_decay=weight_decay, momentum=momentum)\n",
        "  \n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Atdanl9REs3F",
      "metadata": {
        "id": "Atdanl9REs3F"
      },
      "source": [
        "### 2.5 Training Loop and Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ORDqPkiT5r1s",
      "metadata": {
        "id": "ORDqPkiT5r1s"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, device, progress):\n",
        "  \"\"\"\n",
        "    Return:\n",
        "      @best_state: best performance model state parameters\n",
        "      @best_loss: best performance loss\n",
        "  \"\"\"\n",
        "  size = len(dataloader.dataset)\n",
        "  loss_fn = get_class_loss_func()\n",
        "\n",
        "  optimizer = get_optimizer(model, config, progress, adversarial=False)\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    \n",
        "    # compute prediction and loss\n",
        "    class_pred, _ = model(X)\n",
        "\n",
        "    # classification loss\n",
        "    loss = loss_fn(class_pred, y) \n",
        "    curr_loss = loss.item()\n",
        "    \n",
        "    # backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 10 == 0:\n",
        "      current = batch * len(X)\n",
        "      print(f\"## Meter ## current loss: {curr_loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "LlvQLNUDLGJF",
      "metadata": {
        "id": "LlvQLNUDLGJF"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, device):\n",
        "  test_loss, correct = 0, 0\n",
        "  loss_fn = get_class_loss_func()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      class_pred, _ = model(X)\n",
        "\n",
        "      test_loss += loss_fn(class_pred, y).item()\n",
        "      correct += (class_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "  return test_loss, correct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z5uhItnwhj8S",
      "metadata": {
        "id": "z5uhItnwhj8S"
      },
      "source": [
        "### 2.6 Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "nM76Syqahknd",
      "metadata": {
        "id": "nM76Syqahknd"
      },
      "outputs": [],
      "source": [
        "def training(model, train_dataloader, test_dataloader, config, device):\n",
        "  epochs = config['epochs']\n",
        "  # print(f\"Learning_rate {config['lr']}, weight_decay {config['wd']}\")\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n------------------\")\n",
        "    progress = epoch/epochs\n",
        "\n",
        "    train_loop(train_dataloader, model, device, progress)\n",
        "    # test_loss, _ = test_loop(test_dataloader, model, device)\n",
        "\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PIkYlRhi4tkK",
      "metadata": {
        "id": "PIkYlRhi4tkK"
      },
      "source": [
        "## 3 Training without using Domain Adaptation techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 3.1 Product Domain -> Real Life"
      ],
      "metadata": {
        "id": "chQgbFmYorL-"
      },
      "id": "chQgbFmYorL-"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "OCWnRXkc79a4",
      "metadata": {
        "id": "OCWnRXkc79a4"
      },
      "outputs": [],
      "source": [
        "# Get dataloader\n",
        "product_dataset   = get_dataset(product_path)\n",
        "real_life_dataset = get_dataset(real_life_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.1 Training on Source Domain"
      ],
      "metadata": {
        "id": "raxew0mKm-gM"
      },
      "id": "raxew0mKm-gM"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "V93UE4rXi3C9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V93UE4rXi3C9",
        "outputId": "e5f3cc19-d905-452d-c117-de41b49c3b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------------\n",
            "## Meter ## current loss: 3.001915 [    0/ 1601]\n",
            "## Meter ## current loss: 2.295634 [  640/ 1601]\n",
            "## Meter ## current loss: 0.475569 [ 1280/ 1601]\n",
            "Epoch 2\n",
            "------------------\n",
            "## Meter ## current loss: 1.871170 [    0/ 1601]\n",
            "## Meter ## current loss: 0.435511 [  640/ 1601]\n",
            "## Meter ## current loss: 0.344531 [ 1280/ 1601]\n",
            "Epoch 3\n",
            "------------------\n",
            "## Meter ## current loss: 0.366538 [    0/ 1601]\n",
            "## Meter ## current loss: 0.225248 [  640/ 1601]\n",
            "## Meter ## current loss: 0.159612 [ 1280/ 1601]\n",
            "Epoch 4\n",
            "------------------\n",
            "## Meter ## current loss: 0.060553 [    0/ 1601]\n",
            "## Meter ## current loss: 0.240633 [  640/ 1601]\n",
            "## Meter ## current loss: 0.149413 [ 1280/ 1601]\n",
            "Epoch 5\n",
            "------------------\n",
            "## Meter ## current loss: 0.091420 [    0/ 1601]\n",
            "## Meter ## current loss: 0.148792 [  640/ 1601]\n",
            "## Meter ## current loss: 0.052741 [ 1280/ 1601]\n",
            "Epoch 6\n",
            "------------------\n",
            "## Meter ## current loss: 0.086874 [    0/ 1601]\n",
            "## Meter ## current loss: 0.070555 [  640/ 1601]\n",
            "## Meter ## current loss: 0.067607 [ 1280/ 1601]\n",
            "Epoch 7\n",
            "------------------\n",
            "## Meter ## current loss: 0.061730 [    0/ 1601]\n",
            "## Meter ## current loss: 0.037953 [  640/ 1601]\n",
            "## Meter ## current loss: 0.182367 [ 1280/ 1601]\n",
            "Epoch 8\n",
            "------------------\n",
            "## Meter ## current loss: 0.256000 [    0/ 1601]\n",
            "## Meter ## current loss: 0.052480 [  640/ 1601]\n",
            "## Meter ## current loss: 0.075334 [ 1280/ 1601]\n",
            "Epoch 9\n",
            "------------------\n",
            "## Meter ## current loss: 0.064028 [    0/ 1601]\n",
            "## Meter ## current loss: 0.031255 [  640/ 1601]\n",
            "## Meter ## current loss: 0.022999 [ 1280/ 1601]\n",
            "Epoch 10\n",
            "------------------\n",
            "## Meter ## current loss: 0.035783 [    0/ 1601]\n",
            "## Meter ## current loss: 0.060173 [  640/ 1601]\n",
            "## Meter ## current loss: 0.062417 [ 1280/ 1601]\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, test_dataloader = get_dataloader(product_dataset, config['batch_size'])\n",
        "\n",
        "model = DANN(len(product_dataset.classes)).to(device)\n",
        "\n",
        "# Training\n",
        "training(model, train_dataloader, test_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "__d71xhd5SVx",
      "metadata": {
        "id": "__d71xhd5SVx"
      },
      "source": [
        "#### 3.1.2 Test on Real Life"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "E54Vm3jmTRcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E54Vm3jmTRcc",
        "outputId": "36e0c9ad-4615-4626-ca66-18c5de371d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.216673 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.2166732680052519, 0.648)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(real_life_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "# model.load_state_dict(torch.load('model_state.pt', map_location='cpu'))\n",
        "test_loop(loader_target_dataset, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "Cw4GP_z-_iy_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw4GP_z-_iy_",
        "outputId": "c175c37d-5213-4656-97d2-12c50a3faa3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1042058752\n"
          ]
        }
      ],
      "source": [
        "del train_dataloader, test_dataloader, loader_target_dataset\n",
        "del model\n",
        "print(torch.cuda.memory_allocated())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ITPgzgfR5BQB",
      "metadata": {
        "id": "ITPgzgfR5BQB"
      },
      "source": [
        "### 3.2 Real Life -> Product\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.1 Training on Real Life"
      ],
      "metadata": {
        "id": "42FQtZSXoRSI"
      },
      "id": "42FQtZSXoRSI"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "Sb5mqdPMBHli",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb5mqdPMBHli",
        "outputId": "910e7189-2c1d-461b-c01f-16d59d76e9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------------\n",
            "## Meter ## current loss: 2.999211 [    0/ 1601]\n",
            "## Meter ## current loss: 2.756945 [  640/ 1601]\n",
            "## Meter ## current loss: 2.069662 [ 1280/ 1601]\n",
            "Epoch 2\n",
            "------------------\n",
            "## Meter ## current loss: 2.376655 [    0/ 1601]\n",
            "## Meter ## current loss: 1.043095 [  640/ 1601]\n",
            "## Meter ## current loss: 0.794863 [ 1280/ 1601]\n",
            "Epoch 3\n",
            "------------------\n",
            "## Meter ## current loss: 0.605117 [    0/ 1601]\n",
            "## Meter ## current loss: 0.642084 [  640/ 1601]\n",
            "## Meter ## current loss: 0.754907 [ 1280/ 1601]\n",
            "Epoch 4\n",
            "------------------\n",
            "## Meter ## current loss: 0.417951 [    0/ 1601]\n",
            "## Meter ## current loss: 0.400509 [  640/ 1601]\n",
            "## Meter ## current loss: 0.312468 [ 1280/ 1601]\n",
            "Epoch 5\n",
            "------------------\n",
            "## Meter ## current loss: 0.273436 [    0/ 1601]\n",
            "## Meter ## current loss: 0.298855 [  640/ 1601]\n",
            "## Meter ## current loss: 0.263155 [ 1280/ 1601]\n",
            "Epoch 6\n",
            "------------------\n",
            "## Meter ## current loss: 0.208435 [    0/ 1601]\n",
            "## Meter ## current loss: 0.250151 [  640/ 1601]\n",
            "## Meter ## current loss: 0.256588 [ 1280/ 1601]\n",
            "Epoch 7\n",
            "------------------\n",
            "## Meter ## current loss: 0.121052 [    0/ 1601]\n",
            "## Meter ## current loss: 0.095292 [  640/ 1601]\n",
            "## Meter ## current loss: 0.283443 [ 1280/ 1601]\n",
            "Epoch 8\n",
            "------------------\n",
            "## Meter ## current loss: 0.166893 [    0/ 1601]\n",
            "## Meter ## current loss: 0.149674 [  640/ 1601]\n",
            "## Meter ## current loss: 0.154469 [ 1280/ 1601]\n",
            "Epoch 9\n",
            "------------------\n",
            "## Meter ## current loss: 0.116367 [    0/ 1601]\n",
            "## Meter ## current loss: 0.206685 [  640/ 1601]\n",
            "## Meter ## current loss: 0.109971 [ 1280/ 1601]\n",
            "Epoch 10\n",
            "------------------\n",
            "## Meter ## current loss: 0.065242 [    0/ 1601]\n",
            "## Meter ## current loss: 0.146974 [  640/ 1601]\n",
            "## Meter ## current loss: 0.082753 [ 1280/ 1601]\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])\n",
        "\n",
        "model = DANN(len(real_life_dataset.classes)).to(device)\n",
        "\n",
        "# Training\n",
        "training(model, train_dataloader, test_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7HMoVx_85eur",
      "metadata": {
        "id": "7HMoVx_85eur"
      },
      "source": [
        "#### 3.2.2 Testing on Product\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "shPERUI05drr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shPERUI05drr",
        "outputId": "10800da2-22c8-4015-fcd5-d9fecd428492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 81.2%, Avg loss: 0.665499 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.665499288472347, 0.812)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(product_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "# model.load_state_dict(torch.load('model_state.pt', map_location='cpu'))\n",
        "test_loop(loader_target_dataset, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "6aT-zlOq862D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aT-zlOq862D",
        "outputId": "640bf4c2-834e-4404-c59b-3bafe67d7ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1042058752\n"
          ]
        }
      ],
      "source": [
        "del train_dataloader, test_dataloader, loader_target_dataset\n",
        "del model\n",
        "print(torch.cuda.memory_allocated())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7q7jwnwwhRz2",
      "metadata": {
        "id": "7q7jwnwwhRz2"
      },
      "source": [
        "## 4: Define UDA functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "425ysNsFjUy-",
      "metadata": {
        "id": "425ysNsFjUy-"
      },
      "source": [
        "### 4.1 Adversarial Discriminator Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "81ccf625",
      "metadata": {
        "id": "81ccf625"
      },
      "outputs": [],
      "source": [
        "def get_discriminator_loss(source_pred, target_pred): \n",
        "    domain_pred = torch.cat((source_pred, target_pred),dim=0).cuda()\n",
        "    #print(domain_pred.shape) # [128,1024]\n",
        "    source_truth = torch.zeros(len(source_pred))\n",
        "    target_truth = torch.ones(len(target_pred))\n",
        "    domain_truth = torch.cat((source_truth, target_truth),dim=0).cuda()\n",
        "    #print(domain_truth.shape) # [128]\n",
        "\n",
        "    domain_loss = domain_truth*torch.log(1/domain_pred)+(1-domain_truth)*torch.log(1/(1-domain_pred))\n",
        "    domain_loss = domain_loss.mean()\n",
        "\n",
        "    return domain_loss "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BBaNX5GgjK7F",
      "metadata": {
        "id": "BBaNX5GgjK7F"
      },
      "source": [
        "### 4.2 Adversarial optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "zKscrnYohp7k",
      "metadata": {
        "id": "zKscrnYohp7k"
      },
      "outputs": [],
      "source": [
        "def get_adversarial_optimizer(model, config, progress, adversarial=True):\n",
        "  '''\n",
        "  Get Adversarial Optimizers\n",
        "  '''\n",
        "  lr, wd, momtm = config['lr'], config['wd'], config['momentum']\n",
        "  lr = lr / ((1 + config['alpha']*progress)**config['beta'])\n",
        "\n",
        "  feature_ext   = model.get_submodule(\"feature_extractor\")\n",
        "  classifier    = model.get_submodule(\"classifier\")\n",
        "  discriminator = model.get_submodule(\"discriminator\")\n",
        "\n",
        "  pre_trained_weights   = feature_ext.parameters()\n",
        "  classifier_weights    = classifier.parameters()\n",
        "  discriminator_weights = discriminator.parameters()\n",
        "\n",
        "  feature_optim       = torch.optim.SGD([{'params': pre_trained_weights}],     lr=lr/10, weight_decay=wd, momentum=momtm)\n",
        "  classifier_optim    = torch.optim.SGD([{'params': classifier_weights}],      lr=lr,    weight_decay=wd, momentum=momtm)\n",
        "  discriminator_optim = torch.optim.SGD([{'params': discriminator_weights}],   lr=lr,    weight_decay=wd, momentum=momtm)\n",
        "  \n",
        "  return feature_optim, classifier_optim, discriminator_optim "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hRbDuyfU929u",
      "metadata": {
        "id": "hRbDuyfU929u"
      },
      "source": [
        "### 4.3 Adversarial Train Loop\n",
        "\n",
        "Setting the **domain adaptation parameter** according to the original [paper](https://arxiv.org/pdf/1505.07818.pdf) section 5.2.2\n",
        "\n",
        "$$ \\lambda_p = \\frac{2}{1 + exp(-\\gamma \\cdot p)} - 1 $$\n",
        "\n",
        "where p is the training progress linearly changing from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "1SQHSVPE93hi",
      "metadata": {
        "id": "1SQHSVPE93hi"
      },
      "outputs": [],
      "source": [
        "def adversarial_train_loop(source_loader, target_loader, model, config, progress, device):\n",
        "  \"\"\"\n",
        "  return:\n",
        "    @best_state\n",
        "    @best_loss\n",
        "  \"\"\"\n",
        "  size = len(source_loader.dataset)\n",
        "  \n",
        "  # cross entropy loss\n",
        "  classification_loss = get_class_loss_func()\n",
        "\n",
        "  # Get three optimizer\n",
        "  feature_optim, class_optim, discriminator_optim = get_adversarial_optimizer(model, config, progress)\n",
        "\n",
        "  # Target data loader iterator\n",
        "  iter_target = iter(target_loader)\n",
        "\n",
        "  domain_adapt = 2 / (1 + math.exp(-config['gamma']*progress)) - 1\n",
        "\n",
        "  for batch, (X_source, y_source) in enumerate(source_loader):\n",
        "    try:\n",
        "      X_target, _ = next(iter_target)\n",
        "    except:\n",
        "      iter_target = iter(target_loader)\n",
        "      X_target, _ = next(iter_target)  \n",
        "\n",
        "    # Some internal bug return nested tesnor with size 1\n",
        "    if len(X_source) < 64:\n",
        "      continue\n",
        "\n",
        "    X_source, y_source, X_target = X_source.to(device), y_source.to(device), X_target.to(device)\n",
        "\n",
        "    class_pred_source, domain_pred_source = model(X_source)\n",
        "    _,                 domain_pred_target = model(X_target)\n",
        "\n",
        "    class_loss   = classification_loss(class_pred_source, y_source)\n",
        "    discrim_loss = get_discriminator_loss(domain_pred_source, domain_pred_target)\n",
        "\n",
        "    feature_optim.zero_grad()\n",
        "\n",
        "    # Update discriminator\n",
        "    discriminator_optim.zero_grad()\n",
        "    discrim_loss.backward(retain_graph=True)\n",
        "    discriminator_optim.step()\n",
        "\n",
        "    # Update classifier\n",
        "    class_optim.zero_grad()\n",
        "    class_loss.backward(retain_graph=True)\n",
        "    class_optim.step()\n",
        "\n",
        "    # Update feature extractor\n",
        "    feature_optim.step()  \n",
        "\n",
        "    # Total loss\n",
        "    total_loss = class_loss - domain_adapt * discrim_loss \n",
        "\n",
        "    if batch % 10 == 0:\n",
        "      class_loss, discrim_loss, current = class_loss.item(), discrim_loss.item(), batch * len(X_source)\n",
        "      total_loss = total_loss.item()\n",
        "      # print(f\"## Meter  ## [{current:>5d}/{size:>5d}]\")\n",
        "      print(f\"## Meter  ## classification loss: {class_loss:>7f} discrim loss: {discrim_loss:>7f} total loss: {total_loss:>7f}[{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "    del class_loss, discrim_loss \n",
        "    del X_source, y_source, X_target, class_pred_source, domain_pred_source, domain_pred_target\n",
        "  \n",
        "  # return best_state, best_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1jHD6IJ6H8vF",
      "metadata": {
        "id": "1jHD6IJ6H8vF"
      },
      "source": [
        "### 4.4 Adversarial Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "KyhdZbs3H9Ue",
      "metadata": {
        "id": "KyhdZbs3H9Ue"
      },
      "outputs": [],
      "source": [
        "def adversarial_test_loop(dataloader, model, device, name=\"\"):\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  class_loss_func = get_class_loss_func()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      class_pred, _ = model(X)\n",
        "\n",
        "      test_loss += class_loss_func(class_pred, y).item()\n",
        "      correct += (class_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"{name} Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "  return test_loss, correct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tyopBjWr-FAs",
      "metadata": {
        "id": "tyopBjWr-FAs"
      },
      "source": [
        "### 4.5 Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "dBCrfNPj-Bxa",
      "metadata": {
        "id": "dBCrfNPj-Bxa"
      },
      "outputs": [],
      "source": [
        "def adversarial_training(model, source_loader, source_test_loader, target_loader, config, device):\n",
        "  # print(f\"Learning_rate {config['lr']}, weight_decay {config['wd']}\")\n",
        "  # best_loss, best_state = float('inf'), None\n",
        "  no_improve_count = 0\n",
        "\n",
        "  for epoch in range(config['epochs']):\n",
        "    print(f\"Epoch {epoch+1}\\n------------------\")\n",
        "    progress = epoch/config['epochs']\n",
        "\n",
        "    adversarial_train_loop(source_loader, target_loader, model, config, progress, device)\n",
        "\n",
        "    source_loss, _ = adversarial_test_loop(source_test_loader, model, device, \"Source Test\")\n",
        "\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x4ePILfZ4jOA",
      "metadata": {
        "id": "x4ePILfZ4jOA"
      },
      "source": [
        "## 5 Training with UDA Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "wt-IOOThNShC",
      "metadata": {
        "id": "wt-IOOThNShC"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "rcLFqgOelDsW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcLFqgOelDsW",
        "outputId": "3abb6a67-492a-4f3f-cb58-d6dfe63c96dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "adv_model = DANN(len(product_dataset.classes)).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Product -> Real Life"
      ],
      "metadata": {
        "id": "H7QPRLosqltl"
      },
      "id": "H7QPRLosqltl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.1 Training on Product"
      ],
      "metadata": {
        "id": "VKR4440ZqxJV"
      },
      "id": "VKR4440ZqxJV"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "IcUMoe8x_qrC",
      "metadata": {
        "id": "IcUMoe8x_qrC"
      },
      "outputs": [],
      "source": [
        "train_dataloader, train_test_dataloader = get_dataloader(product_dataset, config['batch_size'])\n",
        "target_dataloader, target_test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "ZgN_WIqqPtjk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgN_WIqqPtjk",
        "outputId": "b40a32ac-524e-44a9-ccae-24620517e082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------------\n",
            "## Meter  ## classification loss: 2.987652 discrim loss: 0.694802 total loss: 2.987652[    0/ 1601]\n",
            "## Meter  ## classification loss: 2.334545 discrim loss: 0.694756 total loss: 2.334545[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.661801 discrim loss: 0.695490 total loss: 0.661801[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.495449 \n",
            "\n",
            "Epoch 2\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.689899 discrim loss: 0.696068 total loss: 0.368234[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.402807 discrim loss: 0.695903 total loss: 0.081218[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.449235 discrim loss: 0.694672 total loss: 0.128215[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 91.5%, Avg loss: 0.286462 \n",
            "\n",
            "Epoch 3\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.312988 discrim loss: 0.694647 total loss: -0.216051[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.194318 discrim loss: 0.694985 total loss: -0.334979[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.243429 discrim loss: 0.695009 total loss: -0.285887[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.213573 \n",
            "\n",
            "Epoch 4\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.097166 discrim loss: 0.694549 total loss: -0.531504[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.098419 discrim loss: 0.694906 total loss: -0.530574[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.106883 discrim loss: 0.695299 total loss: -0.522466[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.192439 \n",
            "\n",
            "Epoch 5\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.105571 discrim loss: 0.694986 total loss: -0.564415[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.149285 discrim loss: 0.694767 total loss: -0.520489[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.119769 discrim loss: 0.694490 total loss: -0.549739[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.194619 \n",
            "\n",
            "Epoch 6\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.098384 discrim loss: 0.694875 total loss: -0.587189[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.060199 discrim loss: 0.695023 total loss: -0.625520[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.032982 discrim loss: 0.695365 total loss: -0.653075[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.225686 \n",
            "\n",
            "Epoch 7\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.138128 discrim loss: 0.695464 total loss: -0.553896[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.052987 discrim loss: 0.694952 total loss: -0.638529[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.059568 discrim loss: 0.694969 total loss: -0.631964[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 94.2%, Avg loss: 0.165556 \n",
            "\n",
            "Epoch 8\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.089188 discrim loss: 0.694547 total loss: -0.604093[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.014290 discrim loss: 0.695319 total loss: -0.679763[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.032607 discrim loss: 0.694613 total loss: -0.660741[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 92.0%, Avg loss: 0.211413 \n",
            "\n",
            "Epoch 9\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.043153 discrim loss: 0.694777 total loss: -0.651157[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.037467 discrim loss: 0.695093 total loss: -0.657160[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.067758 discrim loss: 0.694523 total loss: -0.626299[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 94.5%, Avg loss: 0.154319 \n",
            "\n",
            "Epoch 10\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.025357 discrim loss: 0.694569 total loss: -0.669041[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.025249 discrim loss: 0.694794 total loss: -0.669374[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.020241 discrim loss: 0.694567 total loss: -0.674154[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 93.5%, Avg loss: 0.158781 \n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.2 Testing on Real Life"
      ],
      "metadata": {
        "id": "1s0Z_xXXq5gO"
      },
      "id": "1s0Z_xXXq5gO"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "oUUo7mSiJasc",
      "metadata": {
        "id": "oUUo7mSiJasc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd59938-8c43-4ce1-fb0b-305f22576db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 65.2%, Avg loss: 1.197297 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.197297440841794, 0.652)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(real_life_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "test_loop(loader_target_dataset, adv_model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FNofveL_-8gX",
      "metadata": {
        "id": "FNofveL_-8gX"
      },
      "source": [
        "### 5.2 Real Life -> Product"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.1 Training on Real Life"
      ],
      "metadata": {
        "id": "6YxXx0Lzresh"
      },
      "id": "6YxXx0Lzresh"
    },
    {
      "cell_type": "code",
      "source": [
        "del adv_model"
      ],
      "metadata": {
        "id": "b8MUwY3CFb6m"
      },
      "id": "b8MUwY3CFb6m",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "enMKc_Em_tWq",
      "metadata": {
        "id": "enMKc_Em_tWq"
      },
      "outputs": [],
      "source": [
        "train_dataloader, train_test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])\n",
        "target_dataloader, target_test_dataloader = get_dataloader(product_dataset, config['batch_size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "Msifip2P-7UB",
      "metadata": {
        "id": "Msifip2P-7UB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1545d4-fe2b-4010-eb5e-591976a8eaac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------------\n",
            "## Meter  ## classification loss: 3.020483 discrim loss: 0.705278 total loss: 3.020483[    0/ 1601]\n",
            "## Meter  ## classification loss: 2.740297 discrim loss: 0.696857 total loss: 2.740297[  640/ 1601]\n",
            "## Meter  ## classification loss: 2.058019 discrim loss: 0.694749 total loss: 2.058019[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 65.7%, Avg loss: 1.345376 \n",
            "\n",
            "Epoch 2\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.928480 discrim loss: 0.695784 total loss: 0.606946[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.866092 discrim loss: 0.695678 total loss: 0.544607[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.994968 discrim loss: 0.695507 total loss: 0.673562[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 73.4%, Avg loss: 0.860082 \n",
            "\n",
            "Epoch 3\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.500424 discrim loss: 0.696102 total loss: -0.029724[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.511373 discrim loss: 0.695850 total loss: -0.018583[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.643459 discrim loss: 0.695671 total loss: 0.113640[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 76.2%, Avg loss: 0.850830 \n",
            "\n",
            "Epoch 4\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.474419 discrim loss: 0.695083 total loss: -0.154734[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.228261 discrim loss: 0.694882 total loss: -0.400710[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.358023 discrim loss: 0.695586 total loss: -0.271585[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 76.7%, Avg loss: 0.791540 \n",
            "\n",
            "Epoch 5\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.215993 discrim loss: 0.695837 total loss: -0.454814[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.146126 discrim loss: 0.695227 total loss: -0.524091[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.204851 discrim loss: 0.695915 total loss: -0.466031[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 77.2%, Avg loss: 0.817533 \n",
            "\n",
            "Epoch 6\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.272341 discrim loss: 0.695177 total loss: -0.413530[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.154640 discrim loss: 0.695761 total loss: -0.531808[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.176103 discrim loss: 0.695197 total loss: -0.509788[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 0.847407 \n",
            "\n",
            "Epoch 7\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.246388 discrim loss: 0.695262 total loss: -0.445436[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.114326 discrim loss: 0.695707 total loss: -0.577940[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.126341 discrim loss: 0.695200 total loss: -0.565421[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 0.804795 \n",
            "\n",
            "Epoch 8\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.183202 discrim loss: 0.695862 total loss: -0.511392[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.150989 discrim loss: 0.695441 total loss: -0.543185[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.146327 discrim loss: 0.695916 total loss: -0.548321[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 76.7%, Avg loss: 0.785713 \n",
            "\n",
            "Epoch 9\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.083058 discrim loss: 0.695127 total loss: -0.611603[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.087308 discrim loss: 0.695360 total loss: -0.607586[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.158901 discrim loss: 0.695133 total loss: -0.535765[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 77.4%, Avg loss: 0.746317 \n",
            "\n",
            "Epoch 10\n",
            "------------------\n",
            "## Meter  ## classification loss: 0.097831 discrim loss: 0.696079 total loss: -0.598077[    0/ 1601]\n",
            "## Meter  ## classification loss: 0.049781 discrim loss: 0.695275 total loss: -0.645323[  640/ 1601]\n",
            "## Meter  ## classification loss: 0.094128 discrim loss: 0.694877 total loss: -0.600578[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 76.7%, Avg loss: 0.806112 \n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "adv_model = DANN(len(product_dataset.classes)).to(device)\n",
        "adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nSh7gaC8JaVC",
      "metadata": {
        "id": "nSh7gaC8JaVC"
      },
      "source": [
        "#### 5.2.2 Testing on Product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "DfSRjr84-8DF",
      "metadata": {
        "id": "DfSRjr84-8DF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06b8aa9-9fe8-411c-b8b2-89e609cf4ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 0.716414 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7164135620114394, 0.785)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(product_dataset, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "test_loop(loader_target_dataset, adv_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "bFtADV4AtN1Z",
      "metadata": {
        "id": "bFtADV4AtN1Z"
      },
      "outputs": [],
      "source": [
        "# del source_dataset, train_dataloader, test_dataloader, target_dataset, loader_target_dataset\n",
        "del adv_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Summary"
      ],
      "metadata": {
        "id": "YOKgE6LQuqHC"
      },
      "id": "YOKgE6LQuqHC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Product -> Real Life\n"
      ],
      "metadata": {
        "id": "S41pMBv6uy9b"
      },
      "id": "S41pMBv6uy9b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1.1 Purely training on Source Domain-Product\n",
        "\n",
        "Without using any domain adaptation techniques, within 10 epochs training, the classifier network achieves  64.6% accuracy on the target domain."
      ],
      "metadata": {
        "id": "bkflD8rau94r"
      },
      "id": "bkflD8rau94r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1.2 Training on both Source and Target Domains\n",
        "\n",
        "Using DANN doamin adaptation technique, the classifier with feature extractor trained on both source and target domain achives 64.6% accuracy, which is the same as the one trained solely on the source domain, with no improvement on accuracy."
      ],
      "metadata": {
        "id": "vxoGKmCJvHqD"
      },
      "id": "vxoGKmCJvHqD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Real Life -> Product"
      ],
      "metadata": {
        "id": "QTVdi9zvuysa"
      },
      "id": "QTVdi9zvuysa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.1 Purely Training on Source Domain-Real Life\n",
        "\n",
        "The classifier trained solely on the source domain achives 79.2% accuracy on the target domain."
      ],
      "metadata": {
        "id": "_rV09wirvMcM"
      },
      "id": "_rV09wirvMcM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2.2 Training on both Source and Target Domains\n",
        "\n",
        "With feature extractor trained on both source and target domain, the classifer achives 91.9% accuracy on the target domain, which is about 12% improvement over feature extractor purely trained on source domain."
      ],
      "metadata": {
        "id": "VShk9r-GvM2U"
      },
      "id": "VShk9r-GvM2U"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "UDA_GAN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}