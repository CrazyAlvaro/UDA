{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "UOmUNvGYgPRN",
      "metadata": {
        "id": "UOmUNvGYgPRN"
      },
      "source": [
        "# Unsupervised Domain Adaptation Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ExU_wmMAgVsR",
      "metadata": {
        "id": "ExU_wmMAgVsR"
      },
      "source": [
        "## Part-1: Data download\n",
        "Load data to project from Google Drive. Copy a subset of classes of images to the path:\n",
        "- `adaptiope_small/product_images`\n",
        "- `adaptiope_small/real_life` \n",
        "\n",
        "two directories. They represent images from two different domain **product** and **real_life**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4134f6cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4134f6cf",
        "outputId": "3c0f475e-293c-4d0c-89a5-8adf52a2db35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from os import makedirs, listdir\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from os.path import join\n",
        "from shutil import copytree\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!mkdir dataset\n",
        "!cp \"gdrive/My Drive/Colab Notebooks/data/Adaptiope.zip\" dataset/\n",
        "# !ls dataset\n",
        "\n",
        "!unzip -qq dataset/Adaptiope.zip   # unzip file\n",
        "\n",
        "!rm -rf dataset/Adaptiope.zip \n",
        "!rm -rf adaptiope_small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0a6cac67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a6cac67",
        "outputId": "50ffe09e-f25b-44bf-f21a-188fd03ab7ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['magic lamp', 'car jack', 'bicycle', 'hat', 'spatula', 'brachiosaurus', 'rubber boat', 'microwave', 'smoking pipe', 'toothbrush', 'quadcopter', 'crown', 'scissors', 'ice skates', 'mug', 'file cabinet', 'pipe wrench', 'keyboard', 'projector', 'fan', 'usb stick', 'handcuffs', 'glasses', 'hoverboard', 'backpack', 'computer', 'vacuum cleaner', 'stapler', 'notepad', 'hand mixer', 'handgun', 'rc car', 'coat hanger', 'office chair', 'hot glue gun', 'electric shaver', 'game controller', 'scooter', 'hourglass', 'nail clipper', 'comb', 'dart', 'calculator', 'chainsaw', 'binoculars', 'umbrella', 'acoustic guitar', 'helicopter', 'lawn mower', 'monitor', 'rifle', 'tyrannosaurus', 'razor', 'screwdriver', 'stroller', 'printer', 'webcam', 'golf club', 'pen', 'ruler', 'axe', 'telescope', 'fire extinguisher', 'phonograph', 'knife', 'wristwatch', 'diving fins', 'cellphone', 'syringe', 'fighter jet', 'desk lamp', 'skateboard', 'over-ear headphones', 'bicycle helmet', 'drum set', 'vr goggles', 'wheelchair', 'compass', 'bookcase', 'motorbike helmet', 'sword', 'snow shovel', 'watering can', 'purse', 'flat iron', 'tent', 'tank', 'power drill', 'puncher', 'grill', 'sleeping bag', 'baseball bat', 'toilet brush', 'skeleton', 'in-ear headphones', 'ring binder', 'hard-wired fixed phone', 'network switch', 'wallet', 'corkscrew', 'ice cube tray', 'roller skates', 'tape dispenser', 'laptop', 'speakers', 'computer mouse', 'boxing gloves', 'pogo stick', 'ladder', 'stethoscope', 'mixing console', 'power strip', 'letter tray', 'electric guitar', 'trash can', 'shower head', 'smartphone', 'stand mixer', 'cordless fixed phone', 'pikachu', 'sewing machine', 'bottle', 'hair dryer']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:01<00:00, 14.40it/s]\n",
            "100%|██████████| 20/20 [00:01<00:00, 18.34it/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir adaptiope_small\n",
        "classes = listdir(\"Adaptiope/product_images\")\n",
        "print(classes)\n",
        "classes = [\"backpack\", \"bookcase\", \"car jack\", \"comb\", \"crown\", \"file cabinet\", \"flat iron\", \"game controller\", \"glasses\",\n",
        "           \"helicopter\", \"ice skates\", \"letter tray\", \"monitor\", \"mug\", \"network switch\", \"over-ear headphones\", \"pen\",\n",
        "           \"purse\", \"stand mixer\", \"stroller\"]\n",
        "domain_classes = [\"product_images\", \"real_life\"]\n",
        "for d, td in zip([\"Adaptiope/product_images\", \"Adaptiope/real_life\"], [\"adaptiope_small/product_images\", \"adaptiope_small/real_life\"]):\n",
        "  makedirs(td)\n",
        "  for c in tqdm(classes):\n",
        "    c_path = join(d, c)\n",
        "    c_target = join(td, c)\n",
        "    copytree(c_path, c_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uUHNozN6ggRr",
      "metadata": {
        "id": "uUHNozN6ggRr"
      },
      "source": [
        "## Part-2: Image Classification Neural Network\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fwiJOBXWpeS0",
      "metadata": {
        "id": "fwiJOBXWpeS0"
      },
      "source": [
        "### Part-2.0: Data Loading\n",
        "\n",
        "First we load the data and preprocessing them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "hmth8mlu1oov",
      "metadata": {
        "id": "hmth8mlu1oov"
      },
      "outputs": [],
      "source": [
        "product_path = 'adaptiope_small/product_images'\n",
        "real_life_path = 'adaptiope_small/real_life'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ht9bXOHU6zTQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht9bXOHU6zTQ",
        "outputId": "a733e1dd-c163-453a-81ee-54fa75b49aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Adaptiope  adaptiope_small  dataset  gdrive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "_GZxbLlT6O8m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GZxbLlT6O8m",
        "outputId": "537e814e-06d1-4cec-d05e-8a9da7344d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size:  (679, 679)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from os.path import join\n",
        "\n",
        "img = Image.open(join(product_path, 'backpack', 'backpack_003.jpg'))\n",
        "print('Image size: ', img.size)\n",
        "#img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RE2WUwy9BORV",
      "metadata": {
        "id": "RE2WUwy9BORV"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "Vei6SzEeggzU",
      "metadata": {
        "id": "Vei6SzEeggzU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import vgg11, alexnet \n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M5rt9x7nBKiT",
      "metadata": {
        "id": "M5rt9x7nBKiT"
      },
      "source": [
        "configuration constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "JXznFSNkAzn3",
      "metadata": {
        "id": "JXznFSNkAzn3"
      },
      "outputs": [],
      "source": [
        "img_size = 256\n",
        "# mean, std used by pre-trained models from PyTorch\n",
        "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "config = dict(epochs=5, batch_size=64,lr=0.001, wd=0.001, momentum=0.9, domain_regression_weight=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Rz4CI9spEkN",
      "metadata": {
        "id": "_Rz4CI9spEkN"
      },
      "source": [
        "Configue GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "nHv2o65FpDpn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHv2o65FpDpn",
        "outputId": "143965a7-5293-450f-9f63-c57a67cba10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "GF3YyTBAhJk8",
      "metadata": {
        "id": "GF3YyTBAhJk8"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import ToTensor\n",
        "\n",
        "def get_dataset(root_path):\n",
        "  '''\n",
        "    Get dataset from specific data path\n",
        "\n",
        "    # parameters:\n",
        "        root_path: path to image folder\n",
        "\n",
        "    # return: train_loader, test_loader\n",
        "  '''\n",
        "  # Construct image transform\n",
        "  image_transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.CenterCrop(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "  ])\n",
        "\n",
        "  # Load data from filesystem\n",
        "  image_dataset = ImageFolder(root_path, transform=image_transform)\n",
        "\n",
        "  return image_dataset\n",
        "\n",
        "def get_dataloader(dataset, batch_size, shuffle_train=True, shuffle_test=False):\n",
        "  '''\n",
        "    Get DataLoader from specific data path\n",
        "\n",
        "    # parameters:\n",
        "        dataset: ImageFolder instance\n",
        "        batch_size: batch_size for DataLoader\n",
        "        shuffle_train: whether to shuffle training data\n",
        "        shuffle_test: whether to shuffle test data\n",
        "  '''\n",
        "  # Get train, test number\n",
        "  num_total = len(dataset)\n",
        "  num_train = int(num_total * 0.8 + 1)\n",
        "  num_test  = num_total - num_train\n",
        "\n",
        "  # random split dataset\n",
        "  data_train, data_test = random_split(dataset, [num_train, num_test])\n",
        "\n",
        "  # initialize dataloaders\n",
        "  loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=shuffle_train)\n",
        "  loader_test  = DataLoader(data_test, batch_size=batch_size, shuffle=shuffle_test)\n",
        "\n",
        "  return loader_train, loader_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-J4MSc3spcYU",
      "metadata": {
        "id": "-J4MSc3spcYU"
      },
      "source": [
        "### Part-2.1 Pretrain Network\n",
        "\n",
        "Here we use a pretrain Neural Network to start with, then we fine tune it with the data set we have from **Adaptiope** in one domain, and test it on the target domain. Compare the two result, and set the benchmark for later UDA enriched method. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ijDPD_jrvlz_",
      "metadata": {
        "id": "ijDPD_jrvlz_"
      },
      "outputs": [],
      "source": [
        "# pd_dataset = get_dataset(product_path)\n",
        "# len(pd_dataset.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZjWy3ak98L0F",
      "metadata": {
        "id": "ZjWy3ak98L0F"
      },
      "source": [
        "### Part-2.2 Define the Model with Feature Extractor, Classifier, and Domain Regressor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "95ff2db4",
      "metadata": {
        "id": "95ff2db4"
      },
      "outputs": [],
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "\n",
        "    # Feature Extractor with AlexNet\n",
        "    self.feature_extractor = alexnet(pretrained=True)\n",
        "    self.feature_dim = self.feature_extractor.classifier[-1].in_features\n",
        "\n",
        "    # make the last layer identity\n",
        "    self.feature_extractor.classifier[-1] = nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.feature_extractor(x)\n",
        "  \n",
        "  def output_dim(self):\n",
        "    return self.feature_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "517118c3",
      "metadata": {
        "id": "517118c3"
      },
      "outputs": [],
      "source": [
        "from torch import softmax\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, output_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.classifier(X) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "RES6EY4PO7KF",
      "metadata": {
        "id": "RES6EY4PO7KF"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Function\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, tensor):\n",
        "        return tensor.view_as(tensor)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg(), None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "K9syaPhFxOFd",
      "metadata": {
        "id": "K9syaPhFxOFd"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.discriminator =  nn.Sequential(\n",
        "            nn.Linear(int(input_dim), 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024,1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        validity = self.discriminator(x)\n",
        "        return validity "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "BsbwoZkZwjjl",
      "metadata": {
        "id": "BsbwoZkZwjjl"
      },
      "outputs": [],
      "source": [
        "class DANN(nn.Module):\n",
        "  # def __init__(self, num_classes, adversarial=True):\n",
        "  def __init__(self, num_classes):\n",
        "    super(DANN, self).__init__()\n",
        "    self.output_dim = num_classes\n",
        "\n",
        "    # define inner network component\n",
        "    self.feature_extractor = FeatureExtractor()\n",
        "    self.classifier = Classifier(self.feature_extractor.output_dim(), num_classes)\n",
        "    self.discriminator = Discriminator(self.feature_extractor.output_dim())  \n",
        "  \n",
        "  def forward(self, x):\n",
        "    feature_output = self.feature_extractor(x)\n",
        "\n",
        "    class_pred = self.classifier(feature_output)\n",
        "\n",
        "    # Add a ReverseLayer here for negative gradient computation\n",
        "    reverse_feature = ReverseLayerF.apply(feature_output)\n",
        "    domain_pred = self.discriminator(reverse_feature)\n",
        "\n",
        "    return class_pred, domain_pred "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "rOiatGA9xVdu",
      "metadata": {
        "id": "rOiatGA9xVdu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SbvVK4NO68Yp",
      "metadata": {
        "id": "SbvVK4NO68Yp"
      },
      "source": [
        "### Part-2.2.1 Define the Feature Extractor by using a pretrain model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B5xVtgIO8BnL",
      "metadata": {
        "id": "B5xVtgIO8BnL"
      },
      "source": [
        "### Part-2.2.2 Define the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E8fnXyvS8CgD",
      "metadata": {
        "id": "E8fnXyvS8CgD"
      },
      "source": [
        "### Part-2.2.3 Define the Domain Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IhnsX7lq5saz",
      "metadata": {
        "id": "IhnsX7lq5saz"
      },
      "source": [
        "### Part-2.3 Cost function\n",
        "\n",
        "Divide parameters intro two groups, in which the last fully conneted layer with learning_rate, the other layers with 0.1 * learning_rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "q6BkiCH_5sOr",
      "metadata": {
        "id": "q6BkiCH_5sOr"
      },
      "outputs": [],
      "source": [
        "def get_class_loss_func():\n",
        "  return nn.CrossEntropyLoss()\n",
        "\n",
        "# def get_domain_loss_func():\n",
        "  # return torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B-y0dTPj5zrR",
      "metadata": {
        "id": "B-y0dTPj5zrR"
      },
      "source": [
        "### Part-2.4 Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ZsoNnQCq2aEt",
      "metadata": {
        "id": "ZsoNnQCq2aEt"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, config, adversarial=True):\n",
        "  '''\n",
        "  Config Optimizer\n",
        "  '''\n",
        "  learning_rate = config['lr']\n",
        "  weight_decay  = config['wd']\n",
        "  momentum      = config['momentum']\n",
        "\n",
        "  feature_ext   = model.get_submodule(\"feature_extractor\")\n",
        "  classifier    = model.get_submodule(\"classifier\")\n",
        "  discriminator = model.get_submodule(\"discriminator\")\n",
        "\n",
        "  # classification layer name: label_classifier\n",
        "  # classifier_name = \"label_classifier\"\n",
        "  # domain_regressor_name = \"domain_regressor\"\n",
        "  pre_trained_weights = feature_ext.parameters()\n",
        "\n",
        "  if adversarial:\n",
        "    other_weights = list(classifier.parameters()) + list(discriminator.parameters())\n",
        "  else:\n",
        "    other_weights = list(classifier.parameters())\n",
        "\n",
        "  # assign parameters to parameters\n",
        "  optimizer = torch.optim.SGD([\n",
        "    {'params': pre_trained_weights},\n",
        "    {'params': other_weights, 'lr': learning_rate}\n",
        "  ], lr= learning_rate/10, weight_decay=weight_decay, momentum=momentum)\n",
        "  \n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3wL74sCV0Ycm",
      "metadata": {
        "id": "3wL74sCV0Ycm"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Atdanl9REs3F",
      "metadata": {
        "id": "Atdanl9REs3F"
      },
      "source": [
        "### Part-2.5 Training and Testing Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ORDqPkiT5r1s",
      "metadata": {
        "id": "ORDqPkiT5r1s"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, optimizer, device):\n",
        "  size = len(dataloader.dataset)\n",
        "  loss_fn = get_class_loss_func()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    \n",
        "    # compute prediction and loss\n",
        "    class_pred, _ = model(X)\n",
        "\n",
        "    # classification loss\n",
        "    loss = loss_fn(class_pred, y)\n",
        "\n",
        "    # backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "    \n",
        "    del loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "LlvQLNUDLGJF",
      "metadata": {
        "id": "LlvQLNUDLGJF"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, device):\n",
        "  test_loss, correct = 0, 0\n",
        "  loss_fn = get_class_loss_func()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      class_pred, _ = model(X)\n",
        "\n",
        "      test_loss += loss_fn(class_pred, y).item()\n",
        "      correct += (class_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "  return test_loss, correct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z5uhItnwhj8S",
      "metadata": {
        "id": "z5uhItnwhj8S"
      },
      "source": [
        "### Part-2.6 Training & Testing on Target Domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "nM76Syqahknd",
      "metadata": {
        "id": "nM76Syqahknd"
      },
      "outputs": [],
      "source": [
        "def training(model, train_dataloader, test_dataloader, config, device):\n",
        "  epochs = config['epochs']\n",
        "  print(f\"Learning_rate {config['lr']}, weight_decay {config['wd']}\")\n",
        "\n",
        "  optimizer = get_optimizer(model, config, adversarial=False)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n------------------\")\n",
        "    train_loop(train_dataloader, model, optimizer, device)\n",
        "    test_loop(test_dataloader, model, device)\n",
        "\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "OCWnRXkc79a4",
      "metadata": {
        "id": "OCWnRXkc79a4"
      },
      "outputs": [],
      "source": [
        "# Get dataloader\n",
        "product_dataset = get_dataset(product_path)\n",
        "real_life_dataset = get_dataset(real_life_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PIkYlRhi4tkK",
      "metadata": {
        "id": "PIkYlRhi4tkK"
      },
      "source": [
        "### Product -> Real Life\n",
        "#### Train on Product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "V93UE4rXi3C9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "5267b7b0a0204a6bbe515f1d8b259f19",
            "1345a308fad24764b0bd33d650638e4b",
            "f9cb76b7ce9c49a7b24ed9d0cc26492b",
            "a85066aadb884ed591569327972e0b9a",
            "f9a0ba715ed643cbb12c6638c8290685",
            "1b4e46022e1d49e4879bace9b2a4aadc",
            "79052ae28b3241498c5abbc4b564f003",
            "0c80c0b793df47f1be8cc8afe1c0b5ec",
            "1b7f0a8b373740b9b1845f7b0bbfb669",
            "362a4283f57e47c08d67dc53c41c855b",
            "3fb57e1db8704953adf185a184499160"
          ]
        },
        "id": "V93UE4rXi3C9",
        "outputId": "bd9cd1ee-e346-4708-b82c-7fc509b5dd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5267b7b0a0204a6bbe515f1d8b259f19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning_rate 0.001, weight_decay 0.001\n",
            "Epoch 1\n",
            "------------------\n",
            "loss: 3.026970 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 61.2%, Avg loss: 2.707559 \n",
            "\n",
            "Epoch 2\n",
            "------------------\n",
            "loss: 2.640605 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 2.089261 \n",
            "\n",
            "Epoch 3\n",
            "------------------\n",
            "loss: 1.968558 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 1.018701 \n",
            "\n",
            "Epoch 4\n",
            "------------------\n",
            "loss: 1.043317 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.538009 \n",
            "\n",
            "Epoch 5\n",
            "------------------\n",
            "loss: 0.339218 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.422970 \n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, test_dataloader = get_dataloader(product_dataset, 64)\n",
        "\n",
        "model = DANN(len(product_dataset.classes)).to(device)\n",
        "\n",
        "# Training\n",
        "training(model, train_dataloader, test_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "__d71xhd5SVx",
      "metadata": {
        "id": "__d71xhd5SVx"
      },
      "source": [
        "#### Test on Real Life"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "E54Vm3jmTRcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E54Vm3jmTRcc",
        "outputId": "3fd5397f-bda0-418b-a33c-f03d62bc3970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 62.5%, Avg loss: 1.437788 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.437787752598524, 0.6245)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(real_life_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# model.load_state_dict(torch.load('model_state.pt', map_location='cpu'))\n",
        "test_loop(loader_target_dataset, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "Cw4GP_z-_iy_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw4GP_z-_iy_",
        "outputId": "a897f018-e6e0-4a3a-bc4f-3b4e44f1f42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513480192\n"
          ]
        }
      ],
      "source": [
        "del train_dataloader, test_dataloader, loader_target_dataset\n",
        "del model\n",
        "print(torch.cuda.memory_allocated())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ITPgzgfR5BQB",
      "metadata": {
        "id": "ITPgzgfR5BQB"
      },
      "source": [
        "### Real Life -> Product\n",
        "#### Train on Real Life"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "Sb5mqdPMBHli",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb5mqdPMBHli",
        "outputId": "a6847ffe-4f88-49eb-fb79-ad4cdec9fb67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning_rate 0.001, weight_decay 0.001\n",
            "Epoch 1\n",
            "------------------\n",
            "loss: 2.987454 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 21.8%, Avg loss: 2.887071 \n",
            "\n",
            "Epoch 2\n",
            "------------------\n",
            "loss: 2.871017 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 45.6%, Avg loss: 2.698080 \n",
            "\n",
            "Epoch 3\n",
            "------------------\n",
            "loss: 2.674101 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 59.9%, Avg loss: 2.408932 \n",
            "\n",
            "Epoch 4\n",
            "------------------\n",
            "loss: 2.469381 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 64.2%, Avg loss: 1.896553 \n",
            "\n",
            "Epoch 5\n",
            "------------------\n",
            "loss: 1.808306 [    0/ 1601]\n",
            "Test Error: \n",
            " Accuracy: 75.2%, Avg loss: 1.272889 \n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, test_dataloader = get_dataloader(real_life_dataset, 64)\n",
        "\n",
        "model = DANN(len(real_life_dataset.classes)).to(device)\n",
        "\n",
        "# Training\n",
        "training(model, train_dataloader, test_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7HMoVx_85eur",
      "metadata": {
        "id": "7HMoVx_85eur"
      },
      "source": [
        "#### Test on Product\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "shPERUI05drr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shPERUI05drr",
        "outputId": "60466b17-5a0b-49f5-85c6-307e66e15a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 75.2%, Avg loss: 1.180410 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.1804103730246425, 0.752)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(product_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# model.load_state_dict(torch.load('model_state.pt', map_location='cpu'))\n",
        "test_loop(loader_target_dataset, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6aT-zlOq862D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aT-zlOq862D",
        "outputId": "5844b8ae-cdee-48fd-a20b-08ea9efcc8a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513021440\n"
          ]
        }
      ],
      "source": [
        "del train_dataloader, test_dataloader, loader_target_dataset\n",
        "del model\n",
        "print(torch.cuda.memory_allocated())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kTUMJfmMw-tQ",
      "metadata": {
        "id": "kTUMJfmMw-tQ"
      },
      "source": [
        "## TODO\n",
        "\n",
        "TODO: Dataset unzip Google Drive, Copy to folder\n",
        "\n",
        "TODO: Batch progress number error\n",
        "\n",
        "TODO: Early stop or dropout, when accuracy doesn't improve much\n",
        "\n",
        "Otherwise Continue UDA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7q7jwnwwhRz2",
      "metadata": {
        "id": "7q7jwnwwhRz2"
      },
      "source": [
        "## 3: UDA \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "425ysNsFjUy-",
      "metadata": {
        "id": "425ysNsFjUy-"
      },
      "source": [
        "### 3.1 Adversarial Discriminator "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "psgAJw-YhZGJ",
      "metadata": {
        "id": "psgAJw-YhZGJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b380a14e",
      "metadata": {
        "id": "b380a14e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba549cb0",
      "metadata": {
        "id": "ba549cb0"
      },
      "source": [
        "Discriminator Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "81ccf625",
      "metadata": {
        "id": "81ccf625"
      },
      "outputs": [],
      "source": [
        "def get_discriminator_loss(source_pred, target_pred): \n",
        "    domain_pred = torch.cat((source_pred, target_pred),dim=0).cuda()\n",
        "    #print(domain_pred.shape) # [128,1024]\n",
        "    source_truth = torch.zeros(len(source_pred))\n",
        "    target_truth = torch.ones(len(target_pred))\n",
        "    domain_truth = torch.cat((source_truth, target_truth),dim=0).cuda()\n",
        "    #print(domain_truth.shape) # [128]\n",
        "\n",
        "    domain_loss = domain_truth*torch.log(1/domain_pred)+(1-domain_truth)*torch.log(1/(1-domain_pred))\n",
        "    domain_loss = domain_loss.mean()\n",
        "\n",
        "    return domain_loss "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8a0b727",
      "metadata": {
        "id": "c8a0b727"
      },
      "source": [
        "Classification Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BBaNX5GgjK7F",
      "metadata": {
        "id": "BBaNX5GgjK7F"
      },
      "source": [
        "### 3.2 Adversarial optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "zKscrnYohp7k",
      "metadata": {
        "id": "zKscrnYohp7k"
      },
      "outputs": [],
      "source": [
        "def get_adversarial_optimizer(model, config, adversarial=True):\n",
        "  '''\n",
        "  Get Adversarial Optimizers\n",
        "  '''\n",
        "  lr, wd, momtm = config['lr'], config['wd'], config['momentum']\n",
        "\n",
        "  feature_ext   = model.get_submodule(\"feature_extractor\")\n",
        "  classifier    = model.get_submodule(\"classifier\")\n",
        "  discriminator = model.get_submodule(\"discriminator\")\n",
        "\n",
        "  pre_trained_weights   = feature_ext.parameters()\n",
        "  classifier_weights    = classifier.parameters()\n",
        "  discriminator_weights = discriminator.parameters()\n",
        "\n",
        "  feature_optim       = torch.optim.SGD([{'params': pre_trained_weights}],     lr=lr/10, weight_decay=wd, momentum=momtm)\n",
        "  classifier_optim    = torch.optim.SGD([{'params': classifier_weights}],      lr=lr,    weight_decay=wd, momentum=momtm)\n",
        "  discriminator_optim = torch.optim.SGD([{'params': discriminator_weights}],   lr=lr,    weight_decay=wd, momentum=momtm)\n",
        "  \n",
        "  return feature_optim, classifier_optim, discriminator_optim "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ttOqMBEqufWO",
      "metadata": {
        "id": "ttOqMBEqufWO"
      },
      "source": [
        "### 3.3 Domain Regression Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hRbDuyfU929u",
      "metadata": {
        "id": "hRbDuyfU929u"
      },
      "source": [
        "### 3.4 Adversarial Train Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c218bd5e",
      "metadata": {
        "id": "c218bd5e"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "1SQHSVPE93hi",
      "metadata": {
        "id": "1SQHSVPE93hi"
      },
      "outputs": [],
      "source": [
        "def adversarial_train_loop(source_loader, target_loader, model, config, device):\n",
        "  \"\"\"\n",
        "  domain_adapt: lambda in the objective function\n",
        "  \"\"\"\n",
        "  size = len(source_loader.dataset)\n",
        "  domain_weight = config['domain_regression_weight']\n",
        "  \n",
        "  # cross entropy loss\n",
        "  classification_loss = get_class_loss_func()\n",
        "\n",
        "  # Get three optimizer\n",
        "  feature_optim, class_optim, discriminator_optim = get_adversarial_optimizer(model, config)\n",
        "\n",
        "  # Target data loader iterator\n",
        "  iter_target = iter(target_loader)\n",
        "\n",
        "  # TODO: need to use formula\n",
        "  domain_adapt = 1\n",
        "\n",
        "  for batch, (X_source, y_source) in enumerate(source_loader):\n",
        "    try:\n",
        "      X_target, _ = next(iter_target)\n",
        "    except:\n",
        "      iter_target = iter(target_loader)\n",
        "      X_target, _ = next(iter_target)\n",
        "    \n",
        "    \n",
        "\n",
        "    # Some internal bug return nested tesnor with size 1\n",
        "    if len(X_source) < 64:\n",
        "      continue\n",
        "    \n",
        "    # print(\"Len source: \", len(X_source), \" Len target: \", len(X_target))\n",
        "    # if len(X_source) < 64: print(X_source, \" \", X_target)\n",
        "\n",
        "    X_source, y_source, X_target = X_source.to(device), y_source.to(device), X_target.to(device)\n",
        "\n",
        "    class_pred_source, domain_pred_source = model(X_source)\n",
        "    _,                 domain_pred_target = model(X_target)\n",
        "\n",
        "    # print(\"class_pred_source\")\n",
        "    # print(class_pred_source[1])\n",
        "    # print(\"domain_pred_source\")\n",
        "    # print(domain_pred_source[1])\n",
        "    # print(\"domain_pred_target\")\n",
        "    # print(domain_pred_target[1])\n",
        "\n",
        "    # if batch % 2 == 0:\n",
        "      # Train classifier \n",
        "    class_loss   = classification_loss(class_pred_source, y_source)\n",
        "    discrim_loss = get_discriminator_loss(domain_pred_source, domain_pred_target)\n",
        "\n",
        "\n",
        "    feature_optim.zero_grad()\n",
        "\n",
        "    # Update discriminator\n",
        "    discriminator_optim.zero_grad()\n",
        "    discrim_loss.backward(retain_graph=True)\n",
        "    discriminator_optim.step()\n",
        "\n",
        "    # Update classifier\n",
        "    class_optim.zero_grad()\n",
        "    class_loss.backward(retain_graph=True)\n",
        "    class_optim.step()\n",
        "\n",
        "    # Update feature extractor\n",
        "    feature_optim.step()  \n",
        "\n",
        "    # Total loss\n",
        "    total_loss = class_loss - domain_adapt * discrim_loss \n",
        "    \"\"\"\n",
        "    # Update classifier and feature extractor\n",
        "    total_loss = class_loss - domain_adapt * discrim_loss \n",
        "\n",
        "    class_optim.zero_grad()\n",
        "    feature_optim.zero_grad()\n",
        "    # discriminator_optim.zero_grad()\n",
        "\n",
        "    total_loss.backward()\n",
        "\n",
        "    class_optim.step()\n",
        "    feature_optim.step()\n",
        "    # discriminator_optim.step()\n",
        "    \"\"\"\n",
        "\n",
        "    if batch % 10 == 0:\n",
        "      class_loss, discrim_loss, current = class_loss.item(), discrim_loss.item(), batch * len(X_source)\n",
        "      total_loss = total_loss.item()\n",
        "      print(f\"classification loss: {class_loss:>7f} discrim loss: {discrim_loss:>7f} total loss: {total_loss:>7f}[{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "    del class_loss, discrim_loss \n",
        "    del X_source, y_source, X_target, class_pred_source, domain_pred_source, domain_pred_target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518f2406",
      "metadata": {
        "id": "518f2406"
      },
      "source": [
        "#### Total Loss = Classification Loss + Discrimination Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1jHD6IJ6H8vF",
      "metadata": {
        "id": "1jHD6IJ6H8vF"
      },
      "source": [
        "### 3.5 Adversarial Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "KyhdZbs3H9Ue",
      "metadata": {
        "id": "KyhdZbs3H9Ue"
      },
      "outputs": [],
      "source": [
        "def adversarial_test_loop(dataloader, model, device, name=\"\"):\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  class_loss_func = get_class_loss_func()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      class_pred, _ = model(X)\n",
        "\n",
        "      test_loss += class_loss_func(class_pred, y).item()\n",
        "      correct += (class_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"{name} Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "  return test_loss, correct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tyopBjWr-FAs",
      "metadata": {
        "id": "tyopBjWr-FAs"
      },
      "source": [
        "### 3.6 Adversarial training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "dBCrfNPj-Bxa",
      "metadata": {
        "id": "dBCrfNPj-Bxa"
      },
      "outputs": [],
      "source": [
        "def adversarial_training(model, source_loader, source_test_loader, target_loader, config, device):\n",
        "  print(f\"Learning_rate {config['lr']}, weight_decay {config['wd']}\")\n",
        "\n",
        "  for epoch in range(config['epochs']):\n",
        "    print(f\"Epoch {epoch+1}\\n------------------\")\n",
        "    adversarial_train_loop(source_loader, target_loader, model, config, device)\n",
        "    adversarial_test_loop(source_test_loader, model, device, \"Source Test\")\n",
        "    adversarial_test_loop(target_loader, model, device, \"Target Train\")\n",
        "\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kLZMbwjdlDTh",
      "metadata": {
        "id": "kLZMbwjdlDTh"
      },
      "source": [
        "### 3.7 Adversarial Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x4ePILfZ4jOA",
      "metadata": {
        "id": "x4ePILfZ4jOA"
      },
      "source": [
        "### Product ->  Real Life"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "wt-IOOThNShC",
      "metadata": {
        "id": "wt-IOOThNShC"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "rcLFqgOelDsW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcLFqgOelDsW",
        "outputId": "38c48d19-f6da-4bcd-e1ae-72ce9db5564d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "adv_model = DANN(len(product_dataset.classes)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "IcUMoe8x_qrC",
      "metadata": {
        "id": "IcUMoe8x_qrC"
      },
      "outputs": [],
      "source": [
        "train_dataloader, train_test_dataloader = get_dataloader(product_dataset, 64)\n",
        "target_dataloader, target_test_dataloader = get_dataloader(real_life_dataset, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "ZgN_WIqqPtjk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgN_WIqqPtjk",
        "outputId": "a86c7ada-1eb3-4995-b67d-1ee17e6b35f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning_rate 0.001, weight_decay 0.001\n",
            "Epoch 1\n",
            "------------------\n",
            "classification loss: 2.961929 discrim loss: 0.698104 total loss: 2.263826[    0/ 1601]\n",
            "classification loss: 2.945867 discrim loss: 0.695418 total loss: 2.250449[  640/ 1601]\n",
            "classification loss: 2.794593 discrim loss: 0.693935 total loss: 2.100658[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 47.6%, Avg loss: 2.727703 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 2.889599 \n",
            "\n",
            "Epoch 2\n",
            "------------------\n",
            "classification loss: 2.747331 discrim loss: 0.694111 total loss: 2.053219[    0/ 1601]\n",
            "classification loss: 2.628558 discrim loss: 0.694059 total loss: 1.934499[  640/ 1601]\n",
            "classification loss: 2.373319 discrim loss: 0.694176 total loss: 1.679143[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 67.7%, Avg loss: 2.323300 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 44.3%, Avg loss: 2.720714 \n",
            "\n",
            "Epoch 3\n",
            "------------------\n",
            "classification loss: 2.294928 discrim loss: 0.694141 total loss: 1.600787[    0/ 1601]\n",
            "classification loss: 2.126450 discrim loss: 0.694445 total loss: 1.432005[  640/ 1601]\n",
            "classification loss: 1.810847 discrim loss: 0.694401 total loss: 1.116446[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 77.4%, Avg loss: 1.616556 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 2.398327 \n",
            "\n",
            "Epoch 4\n",
            "------------------\n",
            "classification loss: 1.479384 discrim loss: 0.695142 total loss: 0.784243[    0/ 1601]\n",
            "classification loss: 1.349922 discrim loss: 0.694730 total loss: 0.655192[  640/ 1601]\n",
            "classification loss: 1.036829 discrim loss: 0.694621 total loss: 0.342209[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.885603 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 59.5%, Avg loss: 1.948736 \n",
            "\n",
            "Epoch 5\n",
            "------------------\n",
            "classification loss: 0.798116 discrim loss: 0.695176 total loss: 0.102940[    0/ 1601]\n",
            "classification loss: 0.715504 discrim loss: 0.695079 total loss: 0.020426[  640/ 1601]\n",
            "classification loss: 0.674394 discrim loss: 0.696829 total loss: -0.022435[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.588911 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 62.4%, Avg loss: 1.681392 \n",
            "\n",
            "Epoch 6\n",
            "------------------\n",
            "classification loss: 0.388121 discrim loss: 0.695985 total loss: -0.307865[    0/ 1601]\n",
            "classification loss: 0.584726 discrim loss: 0.695046 total loss: -0.110319[  640/ 1601]\n",
            "classification loss: 0.405066 discrim loss: 0.695497 total loss: -0.290432[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.510676 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 63.5%, Avg loss: 1.520664 \n",
            "\n",
            "Epoch 7\n",
            "------------------\n",
            "classification loss: 0.421215 discrim loss: 0.695357 total loss: -0.274142[    0/ 1601]\n",
            "classification loss: 0.412854 discrim loss: 0.695662 total loss: -0.282809[  640/ 1601]\n",
            "classification loss: 0.177099 discrim loss: 0.696204 total loss: -0.519106[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 88.7%, Avg loss: 0.428776 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 61.7%, Avg loss: 1.455876 \n",
            "\n",
            "Epoch 8\n",
            "------------------\n",
            "classification loss: 0.414385 discrim loss: 0.695881 total loss: -0.281496[    0/ 1601]\n",
            "classification loss: 0.362730 discrim loss: 0.695475 total loss: -0.332746[  640/ 1601]\n",
            "classification loss: 0.287596 discrim loss: 0.695143 total loss: -0.407547[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 88.0%, Avg loss: 0.410082 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 63.1%, Avg loss: 1.390800 \n",
            "\n",
            "Epoch 9\n",
            "------------------\n",
            "classification loss: 0.268239 discrim loss: 0.695813 total loss: -0.427574[    0/ 1601]\n",
            "classification loss: 0.344124 discrim loss: 0.695756 total loss: -0.351632[  640/ 1601]\n",
            "classification loss: 0.322429 discrim loss: 0.695022 total loss: -0.372593[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 89.2%, Avg loss: 0.361126 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 62.3%, Avg loss: 1.363412 \n",
            "\n",
            "Epoch 10\n",
            "------------------\n",
            "classification loss: 0.231263 discrim loss: 0.696339 total loss: -0.465077[    0/ 1601]\n",
            "classification loss: 0.188172 discrim loss: 0.695404 total loss: -0.507232[  640/ 1601]\n",
            "classification loss: 0.104942 discrim loss: 0.695693 total loss: -0.590751[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 88.5%, Avg loss: 0.401438 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 63.9%, Avg loss: 1.314929 \n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "config['epochs'] = 10\n",
        "adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "oUUo7mSiJasc",
      "metadata": {
        "id": "oUUo7mSiJasc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7b692f-ed20-4a10-a4ff-faf5a0e89c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 1.355239 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.3552394360303879, 0.6305)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(real_life_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "test_loop(loader_target_dataset, adv_model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FNofveL_-8gX",
      "metadata": {
        "id": "FNofveL_-8gX"
      },
      "source": [
        "#### Real Life -> Product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "enMKc_Em_tWq",
      "metadata": {
        "id": "enMKc_Em_tWq"
      },
      "outputs": [],
      "source": [
        "train_dataloader, train_test_dataloader = get_dataloader(real_life_dataset, 64)\n",
        "target_dataloader, target_test_dataloader = get_dataloader(product_dataset, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "Msifip2P-7UB",
      "metadata": {
        "id": "Msifip2P-7UB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc16db87-7439-4e3a-e429-b5e921d5825a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning_rate 0.001, weight_decay 0.001\n",
            "Epoch 1\n",
            "------------------\n",
            "classification loss: 1.225204 discrim loss: 0.695646 total loss: 0.529557[    0/ 1601]\n",
            "classification loss: 1.199243 discrim loss: 0.695601 total loss: 0.503642[  640/ 1601]\n",
            "classification loss: 1.095573 discrim loss: 0.695219 total loss: 0.400354[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 66.7%, Avg loss: 1.220216 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.290472 \n",
            "\n",
            "Epoch 2\n",
            "------------------\n",
            "classification loss: 0.952599 discrim loss: 0.695886 total loss: 0.256713[    0/ 1601]\n",
            "classification loss: 0.907439 discrim loss: 0.696670 total loss: 0.210769[  640/ 1601]\n",
            "classification loss: 0.873558 discrim loss: 0.696532 total loss: 0.177026[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 69.4%, Avg loss: 1.049284 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 0.272123 \n",
            "\n",
            "Epoch 3\n",
            "------------------\n",
            "classification loss: 0.972146 discrim loss: 0.695485 total loss: 0.276662[    0/ 1601]\n",
            "classification loss: 0.775534 discrim loss: 0.695256 total loss: 0.080278[  640/ 1601]\n",
            "classification loss: 0.822220 discrim loss: 0.695708 total loss: 0.126512[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 70.7%, Avg loss: 1.032456 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 89.6%, Avg loss: 0.312488 \n",
            "\n",
            "Epoch 4\n",
            "------------------\n",
            "classification loss: 0.541883 discrim loss: 0.696161 total loss: -0.154278[    0/ 1601]\n",
            "classification loss: 0.812103 discrim loss: 0.696090 total loss: 0.116013[  640/ 1601]\n",
            "classification loss: 0.562244 discrim loss: 0.695916 total loss: -0.133672[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 69.4%, Avg loss: 0.951339 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.354272 \n",
            "\n",
            "Epoch 5\n",
            "------------------\n",
            "classification loss: 0.813825 discrim loss: 0.696223 total loss: 0.117602[    0/ 1601]\n",
            "classification loss: 0.692961 discrim loss: 0.696771 total loss: -0.003811[  640/ 1601]\n",
            "classification loss: 0.755305 discrim loss: 0.695292 total loss: 0.060013[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 72.7%, Avg loss: 0.859369 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 89.4%, Avg loss: 0.329889 \n",
            "\n",
            "Epoch 6\n",
            "------------------\n",
            "classification loss: 0.705182 discrim loss: 0.695677 total loss: 0.009505[    0/ 1601]\n",
            "classification loss: 0.482243 discrim loss: 0.695909 total loss: -0.213666[  640/ 1601]\n",
            "classification loss: 0.476968 discrim loss: 0.695947 total loss: -0.218979[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 0.974824 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 88.9%, Avg loss: 0.527756 \n",
            "\n",
            "Epoch 7\n",
            "------------------\n",
            "classification loss: 0.543696 discrim loss: 0.696360 total loss: -0.152664[    0/ 1601]\n",
            "classification loss: 0.402196 discrim loss: 0.696031 total loss: -0.293835[  640/ 1601]\n",
            "classification loss: 0.593100 discrim loss: 0.696307 total loss: -0.103207[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 0.884531 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 88.2%, Avg loss: 0.364501 \n",
            "\n",
            "Epoch 8\n",
            "------------------\n",
            "classification loss: 0.511410 discrim loss: 0.695643 total loss: -0.184233[    0/ 1601]\n",
            "classification loss: 0.564802 discrim loss: 0.696929 total loss: -0.132127[  640/ 1601]\n",
            "classification loss: 0.376156 discrim loss: 0.697852 total loss: -0.321695[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 0.869671 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 87.9%, Avg loss: 0.425603 \n",
            "\n",
            "Epoch 9\n",
            "------------------\n",
            "classification loss: 0.542188 discrim loss: 0.696798 total loss: -0.154609[    0/ 1601]\n",
            "classification loss: 0.453354 discrim loss: 0.696167 total loss: -0.242813[  640/ 1601]\n",
            "classification loss: 0.435867 discrim loss: 0.695771 total loss: -0.259904[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 72.2%, Avg loss: 0.849027 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.445937 \n",
            "\n",
            "Epoch 10\n",
            "------------------\n",
            "classification loss: 0.358026 discrim loss: 0.696046 total loss: -0.338020[    0/ 1601]\n",
            "classification loss: 0.266652 discrim loss: 0.696638 total loss: -0.429986[  640/ 1601]\n",
            "classification loss: 0.322876 discrim loss: 0.695442 total loss: -0.372566[ 1280/ 1601]\n",
            "Source Test Test Error: \n",
            " Accuracy: 74.7%, Avg loss: 0.858851 \n",
            "\n",
            "Target Train Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.410254 \n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "config['epochs'] = 10\n",
        "adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "DfSRjr84-8DF",
      "metadata": {
        "id": "DfSRjr84-8DF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dcb499e-648f-4659-e3e1-273096f8f96f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.440376 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4403761252760887, 0.8655)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "loader_target_dataset = DataLoader(real_life_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "test_loop(loader_target_dataset, adv_model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nSh7gaC8JaVC",
      "metadata": {
        "id": "nSh7gaC8JaVC"
      },
      "source": [
        "### 3.8 Testing on Target Domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "bFtADV4AtN1Z",
      "metadata": {
        "id": "bFtADV4AtN1Z"
      },
      "outputs": [],
      "source": [
        "# del source_dataset, train_dataloader, test_dataloader, target_dataset, loader_target_dataset\n",
        "del adv_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CKsMcxgihquu",
      "metadata": {
        "id": "CKsMcxgihquu"
      },
      "source": [
        "## Part-4: Comparison & Discussion\n",
        "Here we compare the test result from the direct method and the UDA method. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6C0fg_GZh4ou",
      "metadata": {
        "id": "6C0fg_GZh4ou"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lcDs1PTfh9G9",
      "metadata": {
        "id": "lcDs1PTfh9G9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u3VyXbyth9sO",
      "metadata": {
        "id": "u3VyXbyth9sO"
      },
      "source": [
        "## Part-5: Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xgSBA7eMh-Nk",
      "metadata": {
        "id": "xgSBA7eMh-Nk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "UDA_GAN.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5267b7b0a0204a6bbe515f1d8b259f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1345a308fad24764b0bd33d650638e4b",
              "IPY_MODEL_f9cb76b7ce9c49a7b24ed9d0cc26492b",
              "IPY_MODEL_a85066aadb884ed591569327972e0b9a"
            ],
            "layout": "IPY_MODEL_f9a0ba715ed643cbb12c6638c8290685"
          }
        },
        "1345a308fad24764b0bd33d650638e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b4e46022e1d49e4879bace9b2a4aadc",
            "placeholder": "​",
            "style": "IPY_MODEL_79052ae28b3241498c5abbc4b564f003",
            "value": "100%"
          }
        },
        "f9cb76b7ce9c49a7b24ed9d0cc26492b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c80c0b793df47f1be8cc8afe1c0b5ec",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b7f0a8b373740b9b1845f7b0bbfb669",
            "value": 244408911
          }
        },
        "a85066aadb884ed591569327972e0b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362a4283f57e47c08d67dc53c41c855b",
            "placeholder": "​",
            "style": "IPY_MODEL_3fb57e1db8704953adf185a184499160",
            "value": " 233M/233M [00:04&lt;00:00, 61.1MB/s]"
          }
        },
        "f9a0ba715ed643cbb12c6638c8290685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4e46022e1d49e4879bace9b2a4aadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79052ae28b3241498c5abbc4b564f003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c80c0b793df47f1be8cc8afe1c0b5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b7f0a8b373740b9b1845f7b0bbfb669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "362a4283f57e47c08d67dc53c41c855b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb57e1db8704953adf185a184499160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}