{"cells":[{"cell_type":"markdown","id":"UOmUNvGYgPRN","metadata":{"id":"UOmUNvGYgPRN"},"source":["# Unsupervised Domain Adaptation Project\n"]},{"cell_type":"markdown","id":"ExU_wmMAgVsR","metadata":{"id":"ExU_wmMAgVsR"},"source":["## 1: Data download\n","Load data to project from Google Drive. Copy a subset of classes of images to the path:\n","- `adaptiope_small/product_images`\n","- `adaptiope_small/real_life` \n","\n","two directories. They represent images from two different domain **product** and **real_life**"]},{"cell_type":"code","execution_count":3,"id":"4134f6cf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4134f6cf","outputId":"35ec72c5-bebe-4f6d-d80f-887843b5af24","executionInfo":{"status":"ok","timestamp":1660117559837,"user_tz":-120,"elapsed":152401,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from os import makedirs, listdir\n","from tqdm import tqdm\n","from google.colab import drive\n","from os.path import join\n","from shutil import copytree\n","\n","drive.mount('/content/gdrive')\n","\n","!mkdir dataset\n","!cp \"gdrive/My Drive/Colab Notebooks/data/Adaptiope.zip\" dataset/\n","# !ls dataset\n","\n","!unzip -qq dataset/Adaptiope.zip   # unzip file\n","\n","!rm -rf dataset/Adaptiope.zip \n","!rm -rf adaptiope_small"]},{"cell_type":"code","execution_count":4,"id":"0a6cac67","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a6cac67","outputId":"0d6064b3-81ae-4b2b-ba71-799c90e8948c","executionInfo":{"status":"ok","timestamp":1660117561489,"user_tz":-120,"elapsed":1665,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['hoverboard', 'wristwatch', 'stethoscope', 'knife', 'screwdriver', 'desk lamp', 'game controller', 'purse', 'ruler', 'bookcase', 'grill', 'telescope', 'fighter jet', 'keyboard', 'magic lamp', 'shower head', 'coat hanger', 'network switch', 'microwave', 'axe', 'rubber boat', 'boxing gloves', 'toothbrush', 'bicycle helmet', 'acoustic guitar', 'stroller', 'scissors', 'skateboard', 'tape dispenser', 'hard-wired fixed phone', 'in-ear headphones', 'ice cube tray', 'letter tray', 'tank', 'chainsaw', 'electric shaver', 'cellphone', 'vr goggles', 'tent', 'stand mixer', 'handgun', 'fan', 'corkscrew', 'power drill', 'stapler', 'power strip', 'puncher', 'scooter', 'usb stick', 'speakers', 'printer', 'crown', 'laptop', 'sewing machine', 'backpack', 'vacuum cleaner', 'smoking pipe', 'bicycle', 'pikachu', 'binoculars', 'lawn mower', 'calculator', 'watering can', 'glasses', 'drum set', 'nail clipper', 'wallet', 'baseball bat', 'monitor', 'rifle', 'fire extinguisher', 'spatula', 'snow shovel', 'over-ear headphones', 'trash can', 'notepad', 'dart', 'mug', 'electric guitar', 'computer', 'bottle', 'pipe wrench', 'hot glue gun', 'skeleton', 'motorbike helmet', 'computer mouse', 'roller skates', 'pen', 'wheelchair', 'flat iron', 'pogo stick', 'webcam', 'projector', 'hand mixer', 'cordless fixed phone', 'razor', 'office chair', 'toilet brush', 'hair dryer', 'ice skates', 'diving fins', 'mixing console', 'compass', 'phonograph', 'sword', 'file cabinet', 'rc car', 'umbrella', 'hourglass', 'ring binder', 'tyrannosaurus', 'syringe', 'ladder', 'brachiosaurus', 'smartphone', 'comb', 'car jack', 'hat', 'golf club', 'quadcopter', 'handcuffs', 'sleeping bag', 'helicopter']\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:01<00:00, 15.84it/s]\n","100%|██████████| 20/20 [00:00<00:00, 25.34it/s]\n"]}],"source":["!mkdir adaptiope_small\n","classes = listdir(\"Adaptiope/product_images\")\n","print(classes)\n","classes = [\"backpack\", \"bookcase\", \"car jack\", \"comb\", \"crown\", \"file cabinet\", \"flat iron\", \"game controller\", \"glasses\",\n","           \"helicopter\", \"ice skates\", \"letter tray\", \"monitor\", \"mug\", \"network switch\", \"over-ear headphones\", \"pen\",\n","           \"purse\", \"stand mixer\", \"stroller\"]\n","domain_classes = [\"product_images\", \"real_life\"]\n","for d, td in zip([\"Adaptiope/product_images\", \"Adaptiope/real_life\"], [\"adaptiope_small/product_images\", \"adaptiope_small/real_life\"]):\n","  makedirs(td)\n","  for c in tqdm(classes):\n","    c_path = join(d, c)\n","    c_target = join(td, c)\n","    copytree(c_path, c_target)"]},{"cell_type":"code","source":["product_path = 'adaptiope_small/product_images'\n","real_life_path = 'adaptiope_small/real_life'"],"metadata":{"id":"S8yOthKskBmC","executionInfo":{"status":"ok","timestamp":1660117561490,"user_tz":-120,"elapsed":7,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"S8yOthKskBmC","execution_count":5,"outputs":[]},{"cell_type":"markdown","id":"uUHNozN6ggRr","metadata":{"id":"uUHNozN6ggRr"},"source":["## 2: Domain-Adversarial training of Neural Network\n","We implement DANN UDA method [DANN](https://arxiv.org/pdf/1505.07818.pdf)\n","\n"," "]},{"cell_type":"markdown","id":"fwiJOBXWpeS0","metadata":{"id":"fwiJOBXWpeS0"},"source":["### 2.0: Import Libraries and Data Loading\n"]},{"cell_type":"code","execution_count":6,"id":"_GZxbLlT6O8m","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GZxbLlT6O8m","outputId":"b0d31bc1-8416-4324-c211-5b441e6c6107","executionInfo":{"status":"ok","timestamp":1660117561911,"user_tz":-120,"elapsed":426,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Image size:  (679, 679)\n"]}],"source":["from PIL import Image\n","from os.path import join\n","import math\n","\n","img = Image.open(join(product_path, 'backpack', 'backpack_003.jpg'))\n","print('Image size: ', img.size)\n","#img"]},{"cell_type":"markdown","id":"RE2WUwy9BORV","metadata":{"id":"RE2WUwy9BORV"},"source":["import libraries"]},{"cell_type":"code","execution_count":7,"id":"Vei6SzEeggzU","metadata":{"id":"Vei6SzEeggzU","executionInfo":{"status":"ok","timestamp":1660117565799,"user_tz":-120,"elapsed":3894,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import softmax\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torchvision.models import vgg11, alexnet \n","from torch.utils.data import DataLoader, random_split\n","from torchvision.transforms.transforms import ToTensor"]},{"cell_type":"markdown","id":"M5rt9x7nBKiT","metadata":{"id":"M5rt9x7nBKiT"},"source":["configuration constants"]},{"cell_type":"code","execution_count":8,"id":"JXznFSNkAzn3","metadata":{"id":"JXznFSNkAzn3","executionInfo":{"status":"ok","timestamp":1660117565800,"user_tz":-120,"elapsed":57,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["img_size = 256\n","# mean, std used by pre-trained models from PyTorch\n","mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","config = dict(epochs=10, batch_size=64,lr=0.01, wd=0.001, momentum=0.9, alpha=10, beta=0.75, gamma=10)"]},{"cell_type":"markdown","id":"_Rz4CI9spEkN","metadata":{"id":"_Rz4CI9spEkN"},"source":["Configue GPU"]},{"cell_type":"code","execution_count":9,"id":"nHv2o65FpDpn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHv2o65FpDpn","outputId":"d09dc00c-f434-4729-cdf8-669bc39d5c27","executionInfo":{"status":"ok","timestamp":1660117565800,"user_tz":-120,"elapsed":54,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":10,"id":"GF3YyTBAhJk8","metadata":{"id":"GF3YyTBAhJk8","executionInfo":{"status":"ok","timestamp":1660117565801,"user_tz":-120,"elapsed":48,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def get_dataset(root_path):\n","  '''\n","    Get dataset from specific data path\n","\n","    # parameters:\n","        root_path: path to image folder\n","\n","    # return: train_loader, test_loader\n","  '''\n","  # Construct image transform\n","  image_transform = transforms.Compose([\n","    transforms.Resize(img_size),\n","    transforms.CenterCrop(img_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","  ])\n","\n","  # Load data from filesystem\n","  image_dataset = ImageFolder(root_path, transform=image_transform)\n","\n","  return image_dataset\n","\n","def get_dataloader(dataset, batch_size, shuffle_train=True, shuffle_test=False):\n","  '''\n","    Get DataLoader from specific data path\n","\n","    # parameters:\n","        dataset: ImageFolder instance\n","        batch_size: batch_size for DataLoader\n","        shuffle_train: whether to shuffle training data\n","        shuffle_test: whether to shuffle test data\n","  '''\n","  # Get train, test number\n","  num_total = len(dataset)\n","  num_train = int(num_total * 0.8 + 1)\n","  num_test  = num_total - num_train\n","\n","  # random split dataset\n","  data_train, data_test = random_split(dataset, [num_train, num_test])\n","\n","  # initialize dataloaders\n","  loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=shuffle_train)\n","  loader_test  = DataLoader(data_test, batch_size=batch_size, shuffle=shuffle_test)\n","\n","  return loader_train, loader_test"]},{"cell_type":"markdown","id":"-J4MSc3spcYU","metadata":{"id":"-J4MSc3spcYU"},"source":["### 2.1 Define Feature Extractor with Pretrain Network"]},{"cell_type":"code","execution_count":11,"id":"95ff2db4","metadata":{"id":"95ff2db4","executionInfo":{"status":"ok","timestamp":1660117565801,"user_tz":-120,"elapsed":46,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["class FeatureExtractor(nn.Module):\n","  def __init__(self):\n","    super(FeatureExtractor, self).__init__()\n","\n","    # Feature Extractor with AlexNet\n","    self.feature_extractor = alexnet(weights='DEFAULT')\n","    self.feature_dim = self.feature_extractor.classifier[-1].in_features\n","\n","    # make the last layer identity\n","    self.feature_extractor.classifier[-1] = nn.Identity()\n","\n","  def forward(self, x):\n","    return self.feature_extractor(x)\n","  \n","  def output_dim(self):\n","    return self.feature_dim"]},{"cell_type":"markdown","id":"ZjWy3ak98L0F","metadata":{"id":"ZjWy3ak98L0F"},"source":["### 2.2 Define Classifier, Discriminator with RevereLayerF for training the Feature Extractor"]},{"cell_type":"code","execution_count":12,"id":"517118c3","metadata":{"id":"517118c3","executionInfo":{"status":"ok","timestamp":1660117565802,"user_tz":-120,"elapsed":45,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["from torch.nn.modules.activation import Softmax\n","class Classifier(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(Classifier, self).__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Linear(input_dim, 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(1024, 512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(512, output_dim),\n","            nn.LogSoftmax(dim=1)\n","        )\n","    \n","    def forward(self, X):\n","        return self.classifier(X) "]},{"cell_type":"code","execution_count":13,"id":"RES6EY4PO7KF","metadata":{"id":"RES6EY4PO7KF","executionInfo":{"status":"ok","timestamp":1660117565802,"user_tz":-120,"elapsed":41,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["from torch.autograd import Function\n","\n","class ReverseLayerF(Function):\n","    @staticmethod\n","    def forward(ctx, tensor):\n","        return tensor.view_as(tensor)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        return grad_output.neg(), None"]},{"cell_type":"code","execution_count":14,"id":"K9syaPhFxOFd","metadata":{"id":"K9syaPhFxOFd","executionInfo":{"status":"ok","timestamp":1660117565802,"user_tz":-120,"elapsed":40,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, input_dim):\n","        super(Discriminator, self).__init__()\n","        self.discriminator =  nn.Sequential(\n","            nn.Linear(int(input_dim), 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(1024,1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        validity = self.discriminator(x)\n","        return validity "]},{"cell_type":"code","execution_count":15,"id":"BsbwoZkZwjjl","metadata":{"id":"BsbwoZkZwjjl","executionInfo":{"status":"ok","timestamp":1660117565803,"user_tz":-120,"elapsed":40,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["class DANN(nn.Module):\n","  # def __init__(self, num_classes, adversarial=True):\n","  def __init__(self, num_classes):\n","    super(DANN, self).__init__()\n","    self.output_dim = num_classes\n","\n","    # define inner network component\n","    self.feature_extractor = FeatureExtractor()\n","    self.classifier = Classifier(self.feature_extractor.output_dim(), num_classes)\n","    self.discriminator = Discriminator(self.feature_extractor.output_dim())  \n","  \n","  def forward(self, x):\n","    feature_output = self.feature_extractor(x)\n","\n","    class_pred = self.classifier(feature_output)\n","\n","    # Add a ReverseLayer here for negative gradient computation\n","    reverse_feature = ReverseLayerF.apply(feature_output)\n","    domain_pred = self.discriminator(reverse_feature)\n","\n","    return class_pred, domain_pred "]},{"cell_type":"markdown","id":"IhnsX7lq5saz","metadata":{"id":"IhnsX7lq5saz"},"source":["### 2.3 Cost function"]},{"cell_type":"code","source":["class BinaryDiceLoss(nn.Module):\n","    \"\"\"Dice loss of binary class\n","    Args:\n","        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n","        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n","        predict: A tensor of shape [N, *]\n","        target: A tensor of shape same with predict\n","        reduction: Reduction method to apply, return mean over batch if 'mean',\n","            return sum if 'sum', return a tensor of shape [N,] if 'none'\n","    Returns:\n","        Loss tensor according to arg reduction\n","    Raise:\n","        Exception if unexpected reduction\n","    \"\"\"\n","    def __init__(self, smooth=1, p=2, reduction='mean'):\n","        super(BinaryDiceLoss, self).__init__()\n","        self.smooth = smooth\n","        self.p = p\n","        self.reduction = reduction\n","\n","    def forward(self, predict, target):\n","        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n","        predict = predict.contiguous().view(predict.shape[0], -1)\n","        target = target.contiguous().view(target.shape[0], -1)\n","\n","        num = torch.sum(torch.mul(predict, target), dim=1) + self.smooth\n","        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\n","\n","        loss = 1 - num / den\n","\n","        if self.reduction == 'mean':\n","            return loss.mean()\n","        elif self.reduction == 'sum':\n","            return loss.sum()\n","        elif self.reduction == 'none':\n","            return loss\n","        else:\n","            raise Exception('Unexpected reduction {}'.format(self.reduction))"],"metadata":{"id":"2uZKaSA3nd7t","executionInfo":{"status":"ok","timestamp":1660117565803,"user_tz":-120,"elapsed":38,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"2uZKaSA3nd7t","execution_count":16,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","class DiceLoss(nn.Module):\n","    \"\"\"Dice loss, need one hot encode input\n","    Args:\n","        weight: An array of shape [num_classes,]\n","        ignore_index: class index to ignore\n","        predict: A tensor of shape [N, C, *]\n","        target: A tensor of same shape with predict\n","        other args pass to BinaryDiceLoss\n","    Return:\n","        same as BinaryDiceLoss\n","    \"\"\"\n","    def __init__(self, weight=None, ignore_index=None, **kwargs):\n","        super(DiceLoss, self).__init__()\n","        self.kwargs = kwargs\n","        self.weight = weight\n","        self.ignore_index = ignore_index\n","\n","    def forward(self, predict, target):\n","        # one hot encode input\n","        num_class = predict.shape[1]\n","        # one hot\n","        target = F.one_hot(target, num_classes=num_class)\n","        \n","        assert predict.shape == target.shape, 'predict & target shape do not match'\n","        dice = BinaryDiceLoss(**self.kwargs)\n","        total_loss = 0\n","        predict = F.softmax(predict, dim=1)\n","\n","        for i in range(target.shape[1]):\n","            if i != self.ignore_index:\n","                dice_loss = dice(predict[:, i], target[:, i])\n","                if self.weight is not None:\n","                    assert self.weight.shape[0] == target.shape[1], \\\n","                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\n","                    dice_loss *= self.weights[i]\n","                total_loss += dice_loss\n","\n","        return total_loss/target.shape[1]"],"metadata":{"id":"N0-rxY3rnh6J","executionInfo":{"status":"ok","timestamp":1660117565804,"user_tz":-120,"elapsed":39,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"N0-rxY3rnh6J","execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"id":"q6BkiCH_5sOr","metadata":{"id":"q6BkiCH_5sOr","executionInfo":{"status":"ok","timestamp":1660117565804,"user_tz":-120,"elapsed":38,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def get_class_loss_func(dice_loss=False):\n","  if dice_loss:\n","    return DiceLoss()\n","  else:\n","    return nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"B-y0dTPj5zrR","metadata":{"id":"B-y0dTPj5zrR"},"source":["### 2.4 Optimizer\n","\n","Setting the **learning rate** according to the original [paper](https://arxiv.org/pdf/1505.07818.pdf) section 5.2.2\n","\n","$$ \\mu_p =  \\frac{\\mu_0}{(1+\\alpha \\cdot p)^\\beta}$$\n","\n","where p is the training progress linearly changing from 0 to 1."]},{"cell_type":"code","execution_count":19,"id":"ZsoNnQCq2aEt","metadata":{"id":"ZsoNnQCq2aEt","executionInfo":{"status":"ok","timestamp":1660117565805,"user_tz":-120,"elapsed":37,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def get_optimizer(model, config, progress, adversarial=True):\n","  '''\n","  Config Optimizer\n","  '''\n","  learning_rate = config['lr']\n","  learning_rate = learning_rate / ((1 + config['alpha']*progress)**config['beta'])\n","\n","  weight_decay  = config['wd']\n","  momentum      = config['momentum']\n","\n","  feature_ext   = model.get_submodule(\"feature_extractor\")\n","  classifier    = model.get_submodule(\"classifier\")\n","  discriminator = model.get_submodule(\"discriminator\")\n","\n","  pre_trained_weights = feature_ext.parameters()\n","\n","  if adversarial:\n","    other_weights = list(classifier.parameters()) + list(discriminator.parameters())\n","  else:\n","    other_weights = list(classifier.parameters())\n","\n","  # assign parameters to parameters\n","  optimizer = torch.optim.SGD([\n","    {'params': pre_trained_weights},\n","    {'params': other_weights, 'lr': learning_rate}\n","  ], lr= learning_rate/10, weight_decay=weight_decay, momentum=momentum)\n","  \n","  return optimizer"]},{"cell_type":"markdown","id":"Atdanl9REs3F","metadata":{"id":"Atdanl9REs3F"},"source":["### 2.5 Training Loop and Testing Loop"]},{"cell_type":"code","execution_count":20,"id":"ORDqPkiT5r1s","metadata":{"id":"ORDqPkiT5r1s","executionInfo":{"status":"ok","timestamp":1660117565805,"user_tz":-120,"elapsed":37,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def train_loop(dataloader, model, device, progress, dice_loss=False):\n","  \"\"\"\n","    Return:\n","      @best_state: best performance model state parameters\n","      @best_loss: best performance loss\n","  \"\"\"\n","  size = len(dataloader.dataset)\n","  loss_fn = get_class_loss_func()\n","\n","  optimizer = get_optimizer(model, config, progress, adversarial=False)\n","\n","  for batch, (X, y) in enumerate(dataloader):\n","    X, y = X.to(device), y.to(device)\n","    \n","    # compute prediction and loss\n","    class_pred, _ = model(X)\n","\n","    # classification loss\n","    loss = loss_fn(class_pred, y) \n","    curr_loss = loss.item()\n","    \n","    # backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch % 10 == 0:\n","      current = batch * len(X)\n","      print(f\"## Meter ## current loss: {curr_loss:>7f} [{current:>5d}/{size:>5d}]\")"]},{"cell_type":"code","execution_count":21,"id":"LlvQLNUDLGJF","metadata":{"id":"LlvQLNUDLGJF","executionInfo":{"status":"ok","timestamp":1660117565805,"user_tz":-120,"elapsed":36,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def test_loop(dataloader, model, device, dice_loss=False):\n","  test_loss, correct = 0, 0\n","  loss_fn = get_class_loss_func()\n","\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      X, y = X.to(device), y.to(device)\n","      class_pred, _ = model(X)\n","\n","      test_loss += loss_fn(class_pred, y).item()\n","      correct += (class_pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader)\n","\n","  test_loss /= num_batches\n","  correct /= size\n","  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","\n","  return test_loss, correct"]},{"cell_type":"markdown","id":"z5uhItnwhj8S","metadata":{"id":"z5uhItnwhj8S"},"source":["### 2.6 Training Function"]},{"cell_type":"code","execution_count":22,"id":"nM76Syqahknd","metadata":{"id":"nM76Syqahknd","executionInfo":{"status":"ok","timestamp":1660117565806,"user_tz":-120,"elapsed":36,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def training(model, train_dataloader, test_dataloader, config, device, dice_loss=False):\n","  epochs = config['epochs']\n","  # print(f\"Learning_rate {config['lr']}, weight_decay {config['wd']}\")\n","\n","  for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}\\n------------------\")\n","    progress = epoch/epochs\n","\n","    train_loop(train_dataloader, model, device, progress)\n","    # test_loss, _ = test_loop(test_dataloader, model, device)\n","\n","  print(\"Done\")"]},{"cell_type":"markdown","id":"PIkYlRhi4tkK","metadata":{"id":"PIkYlRhi4tkK"},"source":["## 3 Training without using Domain Adaptation techniques"]},{"cell_type":"markdown","source":[" ### 3.1 Product Domain -> Real Life"],"metadata":{"id":"chQgbFmYorL-"},"id":"chQgbFmYorL-"},{"cell_type":"code","execution_count":23,"id":"OCWnRXkc79a4","metadata":{"id":"OCWnRXkc79a4","executionInfo":{"status":"ok","timestamp":1660117565806,"user_tz":-120,"elapsed":35,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["# Get dataloader\n","product_dataset   = get_dataset(product_path)\n","real_life_dataset = get_dataset(real_life_path)"]},{"cell_type":"markdown","source":["#### 3.1.1 Training on Source Domain"],"metadata":{"id":"raxew0mKm-gM"},"id":"raxew0mKm-gM"},{"cell_type":"code","execution_count":24,"id":"V93UE4rXi3C9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":951,"referenced_widgets":["26281c309c5b44cb8a192b66deccbdec","a8c973d3e34044f08090d19372fb8dff","786a38756c47432fa545b3e868bda1e3","ee51668878e048989dbd6e0f76e8f655","3aa4cb67fc954f9991499332337e9712","860230e73f55419183849201358e6835","16c63f18a2b343168b076a9009f3bb9c","de62612dff164f178dc01fb8d48f67b5","3aaeb2426e114af5b3f3ef8bbdedf424","6f6bea95a3f242dca83d8925b75ea2b8","ccaaf8bbcda44268b099d4ff66fc173b"]},"id":"V93UE4rXi3C9","outputId":"4d395b62-cd96-4e29-cfe6-8038e494f949","executionInfo":{"status":"ok","timestamp":1660117894250,"user_tz":-120,"elapsed":328478,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/233M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26281c309c5b44cb8a192b66deccbdec"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1\n","------------------\n","## Meter ## current loss: 2.969600 [    0/ 1601]\n","## Meter ## current loss: 2.374293 [  640/ 1601]\n","## Meter ## current loss: 0.667915 [ 1280/ 1601]\n","Epoch 2\n","------------------\n","## Meter ## current loss: 3.042634 [    0/ 1601]\n","## Meter ## current loss: 0.791877 [  640/ 1601]\n","## Meter ## current loss: 0.303730 [ 1280/ 1601]\n","Epoch 3\n","------------------\n","## Meter ## current loss: 0.542020 [    0/ 1601]\n","## Meter ## current loss: 0.290702 [  640/ 1601]\n","## Meter ## current loss: 0.202121 [ 1280/ 1601]\n","Epoch 4\n","------------------\n","## Meter ## current loss: 0.236690 [    0/ 1601]\n","## Meter ## current loss: 0.092328 [  640/ 1601]\n","## Meter ## current loss: 0.135721 [ 1280/ 1601]\n","Epoch 5\n","------------------\n","## Meter ## current loss: 0.116931 [    0/ 1601]\n","## Meter ## current loss: 0.149550 [  640/ 1601]\n","## Meter ## current loss: 0.129107 [ 1280/ 1601]\n","Epoch 6\n","------------------\n","## Meter ## current loss: 0.068333 [    0/ 1601]\n","## Meter ## current loss: 0.041600 [  640/ 1601]\n","## Meter ## current loss: 0.268589 [ 1280/ 1601]\n","Epoch 7\n","------------------\n","## Meter ## current loss: 0.086807 [    0/ 1601]\n","## Meter ## current loss: 0.138809 [  640/ 1601]\n","## Meter ## current loss: 0.069879 [ 1280/ 1601]\n","Epoch 8\n","------------------\n","## Meter ## current loss: 0.064751 [    0/ 1601]\n","## Meter ## current loss: 0.076939 [  640/ 1601]\n","## Meter ## current loss: 0.027299 [ 1280/ 1601]\n","Epoch 9\n","------------------\n","## Meter ## current loss: 0.109532 [    0/ 1601]\n","## Meter ## current loss: 0.033918 [  640/ 1601]\n","## Meter ## current loss: 0.043043 [ 1280/ 1601]\n","Epoch 10\n","------------------\n","## Meter ## current loss: 0.072240 [    0/ 1601]\n","## Meter ## current loss: 0.031506 [  640/ 1601]\n","## Meter ## current loss: 0.050239 [ 1280/ 1601]\n","Done\n"]}],"source":["train_dataloader, test_dataloader = get_dataloader(product_dataset, config['batch_size'])\n","\n","model = DANN(len(product_dataset.classes)).to(device)\n","\n","# Training\n","training(model, train_dataloader, test_dataloader, config, device)"]},{"cell_type":"markdown","id":"__d71xhd5SVx","metadata":{"id":"__d71xhd5SVx"},"source":["#### 3.1.2 Test on Real Life"]},{"cell_type":"code","execution_count":25,"id":"E54Vm3jmTRcc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E54Vm3jmTRcc","outputId":"846794fb-fe01-48e6-e4dc-99b26c9b9ac5","executionInfo":{"status":"ok","timestamp":1660117960867,"user_tz":-120,"elapsed":66638,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 63.7%, Avg loss: 1.228601 \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(1.2286008251830935, 0.637)"]},"metadata":{},"execution_count":25}],"source":["loader_target_dataset = DataLoader(real_life_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","# model.load_state_dict(torch.load('model_state.pt', map_location='cpu'))\n","test_loop(loader_target_dataset, model, device)"]},{"cell_type":"code","execution_count":26,"id":"Cw4GP_z-_iy_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cw4GP_z-_iy_","outputId":"47f40bd4-9aab-471d-81ec-6adb2d8e7de4","executionInfo":{"status":"ok","timestamp":1660117960868,"user_tz":-120,"elapsed":16,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["513480192\n"]}],"source":["del train_dataloader, test_dataloader, loader_target_dataset\n","del model\n","print(torch.cuda.memory_allocated())"]},{"cell_type":"markdown","id":"ITPgzgfR5BQB","metadata":{"id":"ITPgzgfR5BQB"},"source":["### 3.2 Real Life -> Product\n"]},{"cell_type":"markdown","source":["#### 3.2.1 Training on Real Life"],"metadata":{"id":"42FQtZSXoRSI"},"id":"42FQtZSXoRSI"},{"cell_type":"code","execution_count":27,"id":"Sb5mqdPMBHli","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sb5mqdPMBHli","outputId":"5c1adf46-86c6-408a-d505-3454dd3aa282","executionInfo":{"status":"ok","timestamp":1660118498845,"user_tz":-120,"elapsed":537990,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","------------------\n","## Meter ## current loss: 3.015364 [    0/ 1601]\n","## Meter ## current loss: 2.728484 [  640/ 1601]\n","## Meter ## current loss: 2.072116 [ 1280/ 1601]\n","Epoch 2\n","------------------\n","## Meter ## current loss: 1.250300 [    0/ 1601]\n","## Meter ## current loss: 1.229087 [  640/ 1601]\n","## Meter ## current loss: 0.744018 [ 1280/ 1601]\n","Epoch 3\n","------------------\n","## Meter ## current loss: 0.605536 [    0/ 1601]\n","## Meter ## current loss: 0.621318 [  640/ 1601]\n","## Meter ## current loss: 0.503447 [ 1280/ 1601]\n","Epoch 4\n","------------------\n","## Meter ## current loss: 0.306284 [    0/ 1601]\n","## Meter ## current loss: 0.410999 [  640/ 1601]\n","## Meter ## current loss: 0.346206 [ 1280/ 1601]\n","Epoch 5\n","------------------\n","## Meter ## current loss: 1.159203 [    0/ 1601]\n","## Meter ## current loss: 0.474070 [  640/ 1601]\n","## Meter ## current loss: 0.406240 [ 1280/ 1601]\n","Epoch 6\n","------------------\n","## Meter ## current loss: 0.267251 [    0/ 1601]\n","## Meter ## current loss: 0.210166 [  640/ 1601]\n","## Meter ## current loss: 0.137158 [ 1280/ 1601]\n","Epoch 7\n","------------------\n","## Meter ## current loss: 0.221408 [    0/ 1601]\n","## Meter ## current loss: 0.226491 [  640/ 1601]\n","## Meter ## current loss: 0.204366 [ 1280/ 1601]\n","Epoch 8\n","------------------\n","## Meter ## current loss: 0.159368 [    0/ 1601]\n","## Meter ## current loss: 0.127535 [  640/ 1601]\n","## Meter ## current loss: 0.168483 [ 1280/ 1601]\n","Epoch 9\n","------------------\n","## Meter ## current loss: 0.230073 [    0/ 1601]\n","## Meter ## current loss: 0.095311 [  640/ 1601]\n","## Meter ## current loss: 0.084328 [ 1280/ 1601]\n","Epoch 10\n","------------------\n","## Meter ## current loss: 0.166305 [    0/ 1601]\n","## Meter ## current loss: 0.154872 [  640/ 1601]\n","## Meter ## current loss: 0.109330 [ 1280/ 1601]\n","Done\n"]}],"source":["train_dataloader, test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])\n","\n","model = DANN(len(real_life_dataset.classes)).to(device)\n","\n","# Training\n","training(model, train_dataloader, test_dataloader, config, device)"]},{"cell_type":"markdown","id":"7HMoVx_85eur","metadata":{"id":"7HMoVx_85eur"},"source":["#### 3.2.2 Testing on Product\n"]},{"cell_type":"code","execution_count":28,"id":"shPERUI05drr","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shPERUI05drr","outputId":"3e30228e-cceb-46fc-9f31-b03c81253dbe","executionInfo":{"status":"ok","timestamp":1660118537309,"user_tz":-120,"elapsed":38470,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 80.7%, Avg loss: 0.659917 \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.6599167459935416, 0.8065)"]},"metadata":{},"execution_count":28}],"source":["loader_target_dataset = DataLoader(product_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","# model.load_state_dict(torch.load('model_state.pt', map_location='cpu'))\n","test_loop(loader_target_dataset, model, device)"]},{"cell_type":"code","execution_count":29,"id":"6aT-zlOq862D","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aT-zlOq862D","outputId":"34b4f602-3b2a-44d3-8984-f1bac5001cfc","executionInfo":{"status":"ok","timestamp":1660118537310,"user_tz":-120,"elapsed":19,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["513021440\n"]}],"source":["del train_dataloader, test_dataloader, loader_target_dataset\n","del model\n","print(torch.cuda.memory_allocated())"]},{"cell_type":"markdown","source":["Dice Training"],"metadata":{"id":"NQ3itxnUpIwh"},"id":"NQ3itxnUpIwh"},{"cell_type":"code","source":["train_dataloader, test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])\n","\n","model = DANN(len(real_life_dataset.classes)).to(device)\n","# Training\n","dice_config = dict(epochs=10, batch_size=256, lr=0.1, wd=0.001, momentum=0.9, alpha=10, beta=0.75, gamma=10)\n","training(model, train_dataloader, test_dataloader, dice_config, device, dice_loss=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oT7eO7CkpNKd","executionInfo":{"status":"ok","timestamp":1660119075886,"user_tz":-120,"elapsed":538591,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}},"outputId":"ce77f821-80fa-46f5-e917-6f2ff2bfa94d"},"id":"oT7eO7CkpNKd","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","------------------\n","## Meter ## current loss: 3.010717 [    0/ 1601]\n","## Meter ## current loss: 2.743840 [  640/ 1601]\n","## Meter ## current loss: 1.994464 [ 1280/ 1601]\n","Epoch 2\n","------------------\n","## Meter ## current loss: 0.983435 [    0/ 1601]\n","## Meter ## current loss: 0.805589 [  640/ 1601]\n","## Meter ## current loss: 0.866838 [ 1280/ 1601]\n","Epoch 3\n","------------------\n","## Meter ## current loss: 0.472337 [    0/ 1601]\n","## Meter ## current loss: 0.463499 [  640/ 1601]\n","## Meter ## current loss: 0.413025 [ 1280/ 1601]\n","Epoch 4\n","------------------\n","## Meter ## current loss: 0.353862 [    0/ 1601]\n","## Meter ## current loss: 0.447898 [  640/ 1601]\n","## Meter ## current loss: 0.251958 [ 1280/ 1601]\n","Epoch 5\n","------------------\n","## Meter ## current loss: 0.228203 [    0/ 1601]\n","## Meter ## current loss: 0.222434 [  640/ 1601]\n","## Meter ## current loss: 0.272569 [ 1280/ 1601]\n","Epoch 6\n","------------------\n","## Meter ## current loss: 0.294113 [    0/ 1601]\n","## Meter ## current loss: 0.201670 [  640/ 1601]\n","## Meter ## current loss: 0.335984 [ 1280/ 1601]\n","Epoch 7\n","------------------\n","## Meter ## current loss: 0.173527 [    0/ 1601]\n","## Meter ## current loss: 0.240886 [  640/ 1601]\n","## Meter ## current loss: 0.198297 [ 1280/ 1601]\n","Epoch 8\n","------------------\n","## Meter ## current loss: 0.139523 [    0/ 1601]\n","## Meter ## current loss: 0.140791 [  640/ 1601]\n","## Meter ## current loss: 0.163078 [ 1280/ 1601]\n","Epoch 9\n","------------------\n","## Meter ## current loss: 0.127982 [    0/ 1601]\n","## Meter ## current loss: 0.051897 [  640/ 1601]\n","## Meter ## current loss: 0.082129 [ 1280/ 1601]\n","Epoch 10\n","------------------\n","## Meter ## current loss: 0.113048 [    0/ 1601]\n","## Meter ## current loss: 0.110417 [  640/ 1601]\n","## Meter ## current loss: 0.058716 [ 1280/ 1601]\n","Done\n"]}]},{"cell_type":"markdown","id":"7q7jwnwwhRz2","metadata":{"id":"7q7jwnwwhRz2"},"source":["## 4: Define UDA functions\n"]},{"cell_type":"markdown","id":"425ysNsFjUy-","metadata":{"id":"425ysNsFjUy-"},"source":["### 4.1 Adversarial Discriminator Loss"]},{"cell_type":"code","execution_count":31,"id":"81ccf625","metadata":{"id":"81ccf625","executionInfo":{"status":"ok","timestamp":1660119075887,"user_tz":-120,"elapsed":17,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def get_discriminator_loss(source_pred, target_pred): \n","    domain_pred = torch.cat((source_pred, target_pred),dim=0).cuda()\n","    #print(domain_pred.shape) # [128,1024]\n","    source_truth = torch.zeros(len(source_pred))\n","    target_truth = torch.ones(len(target_pred))\n","    domain_truth = torch.cat((source_truth, target_truth),dim=0).cuda()\n","    #print(domain_truth.shape) # [128]\n","\n","    domain_loss = domain_truth*torch.log(1/domain_pred)+(1-domain_truth)*torch.log(1/(1-domain_pred))\n","    domain_loss = domain_loss.mean()\n","\n","    return domain_loss "]},{"cell_type":"markdown","id":"BBaNX5GgjK7F","metadata":{"id":"BBaNX5GgjK7F"},"source":["### 4.2 Adversarial optimizer"]},{"cell_type":"code","execution_count":32,"id":"zKscrnYohp7k","metadata":{"id":"zKscrnYohp7k","executionInfo":{"status":"ok","timestamp":1660119075887,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def get_adversarial_optimizer(model, config, progress, adversarial=True):\n","  '''\n","  Get Adversarial Optimizers\n","  '''\n","  lr, wd, momtm = config['lr'], config['wd'], config['momentum']\n","  lr = lr / ((1 + config['alpha']*progress)**config['beta'])\n","\n","  feature_ext   = model.get_submodule(\"feature_extractor\")\n","  classifier    = model.get_submodule(\"classifier\")\n","  discriminator = model.get_submodule(\"discriminator\")\n","\n","  pre_trained_weights   = feature_ext.parameters()\n","  classifier_weights    = classifier.parameters()\n","  discriminator_weights = discriminator.parameters()\n","\n","  feature_optim       = torch.optim.SGD([{'params': pre_trained_weights}],     lr=lr/10, weight_decay=wd, momentum=momtm)\n","  classifier_optim    = torch.optim.SGD([{'params': classifier_weights}],      lr=lr,    weight_decay=wd, momentum=momtm)\n","  discriminator_optim = torch.optim.SGD([{'params': discriminator_weights}],   lr=lr,    weight_decay=wd, momentum=momtm)\n","  \n","  return feature_optim, classifier_optim, discriminator_optim "]},{"cell_type":"markdown","id":"hRbDuyfU929u","metadata":{"id":"hRbDuyfU929u"},"source":["### 4.3 Adversarial Train Loop\n","\n","Setting the **domain adaptation parameter** according to the original [paper](https://arxiv.org/pdf/1505.07818.pdf) section 5.2.2\n","\n","$$ \\lambda_p = \\frac{2}{1 + exp(-\\gamma \\cdot p)} - 1 $$\n","\n","where p is the training progress linearly changing from 0 to 1."]},{"cell_type":"code","execution_count":33,"id":"1SQHSVPE93hi","metadata":{"id":"1SQHSVPE93hi","executionInfo":{"status":"ok","timestamp":1660119075887,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def adversarial_train_loop(source_loader, target_loader, model, config, progress, device):\n","  \"\"\"\n","  return:\n","    @best_state\n","    @best_loss\n","  \"\"\"\n","  size = len(source_loader.dataset)\n","  \n","  # cross entropy loss\n","  classification_loss = get_class_loss_func()\n","\n","  # Get three optimizer\n","  feature_optim, class_optim, discriminator_optim = get_adversarial_optimizer(model, config, progress)\n","\n","  # Target data loader iterator\n","  iter_target = iter(target_loader)\n","\n","  domain_adapt = 2 / (1 + math.exp(-config['gamma']*progress)) - 1\n","\n","  for batch, (X_source, y_source) in enumerate(source_loader):\n","    try:\n","      X_target, _ = next(iter_target)\n","    except:\n","      iter_target = iter(target_loader)\n","      X_target, _ = next(iter_target)  \n","\n","    # Some internal bug return nested tesnor with size 1\n","    if len(X_source) < 64:\n","      continue\n","\n","    X_source, y_source, X_target = X_source.to(device), y_source.to(device), X_target.to(device)\n","\n","    class_pred_source, domain_pred_source = model(X_source)\n","    _,                 domain_pred_target = model(X_target)\n","\n","    class_loss   = classification_loss(class_pred_source, y_source)\n","    discrim_loss = get_discriminator_loss(domain_pred_source, domain_pred_target)\n","\n","    feature_optim.zero_grad()\n","\n","    # Update discriminator\n","    discriminator_optim.zero_grad()\n","    discrim_loss.backward(retain_graph=True)\n","    discriminator_optim.step()\n","\n","    # Update classifier\n","    class_optim.zero_grad()\n","    class_loss.backward(retain_graph=True)\n","    class_optim.step()\n","\n","    # Update feature extractor\n","    feature_optim.step()  \n","\n","    # Total loss\n","    total_loss = class_loss - domain_adapt * discrim_loss \n","\n","    if batch % 10 == 0:\n","      class_loss, discrim_loss, current = class_loss.item(), discrim_loss.item(), batch * len(X_source)\n","      total_loss = total_loss.item()\n","      # print(f\"## Meter  ## [{current:>5d}/{size:>5d}]\")\n","      print(f\"## Meter  ## classification loss: {class_loss:>7f} discrim loss: {discrim_loss:>7f} total loss: {total_loss:>7f}[{current:>5d}/{size:>5d}]\")\n","\n","    del class_loss, discrim_loss \n","    del X_source, y_source, X_target, class_pred_source, domain_pred_source, domain_pred_target\n","  \n","  # return best_state, best_loss"]},{"cell_type":"markdown","id":"1jHD6IJ6H8vF","metadata":{"id":"1jHD6IJ6H8vF"},"source":["### 4.4 Adversarial Test Loop"]},{"cell_type":"code","execution_count":34,"id":"KyhdZbs3H9Ue","metadata":{"id":"KyhdZbs3H9Ue","executionInfo":{"status":"ok","timestamp":1660119075888,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def adversarial_test_loop(dataloader, model, device, name=\"\"):\n","  test_loss, correct = 0, 0\n","\n","  class_loss_func = get_class_loss_func()\n","\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      X, y = X.to(device), y.to(device)\n","      class_pred, _ = model(X)\n","\n","      test_loss += class_loss_func(class_pred, y).item()\n","      correct += (class_pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader)\n","\n","  test_loss /= num_batches\n","  correct /= size\n","  print(f\"{name} Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","\n","  return test_loss, correct"]},{"cell_type":"markdown","id":"tyopBjWr-FAs","metadata":{"id":"tyopBjWr-FAs"},"source":["### 4.5 Adversarial Training"]},{"cell_type":"code","execution_count":35,"id":"dBCrfNPj-Bxa","metadata":{"id":"dBCrfNPj-Bxa","executionInfo":{"status":"ok","timestamp":1660119075888,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["def adversarial_training(model, source_loader, source_test_loader, target_loader, config, device):\n","  # print(f\"Learning_rate {config['lr']}, weight_decay {config['wd']}\")\n","  # best_loss, best_state = float('inf'), None\n","  no_improve_count = 0\n","\n","  for epoch in range(config['epochs']):\n","    print(f\"Epoch {epoch+1}\\n------------------\")\n","    progress = epoch/config['epochs']\n","\n","    adversarial_train_loop(source_loader, target_loader, model, config, progress, device)\n","\n","    source_loss, _ = adversarial_test_loop(source_test_loader, model, device, \"Source Test\")\n","\n","  print(\"Done\")"]},{"cell_type":"markdown","id":"x4ePILfZ4jOA","metadata":{"id":"x4ePILfZ4jOA"},"source":["## 5 Training with UDA Techniques"]},{"cell_type":"code","execution_count":36,"id":"wt-IOOThNShC","metadata":{"id":"wt-IOOThNShC","executionInfo":{"status":"ok","timestamp":1660119075888,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":37,"id":"rcLFqgOelDsW","metadata":{"id":"rcLFqgOelDsW","executionInfo":{"status":"ok","timestamp":1660119076309,"user_tz":-120,"elapsed":427,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["adv_model = DANN(len(product_dataset.classes)).to(device)"]},{"cell_type":"markdown","source":["### 5.1 Product -> Real Life"],"metadata":{"id":"H7QPRLosqltl"},"id":"H7QPRLosqltl"},{"cell_type":"markdown","source":["#### 5.1.1 Training on Product"],"metadata":{"id":"VKR4440ZqxJV"},"id":"VKR4440ZqxJV"},{"cell_type":"code","execution_count":38,"id":"IcUMoe8x_qrC","metadata":{"id":"IcUMoe8x_qrC","executionInfo":{"status":"ok","timestamp":1660119076309,"user_tz":-120,"elapsed":4,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["train_dataloader, train_test_dataloader = get_dataloader(product_dataset, config['batch_size'])\n","target_dataloader, target_test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])"]},{"cell_type":"code","execution_count":39,"id":"ZgN_WIqqPtjk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgN_WIqqPtjk","outputId":"05917a8d-f61d-4451-cc4e-a9357826c92f","executionInfo":{"status":"ok","timestamp":1660120058011,"user_tz":-120,"elapsed":981706,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","------------------\n","## Meter  ## classification loss: 3.012991 discrim loss: 0.696010 total loss: 3.012991[    0/ 1601]\n","## Meter  ## classification loss: 2.301223 discrim loss: 0.694513 total loss: 2.301223[  640/ 1601]\n","## Meter  ## classification loss: 0.831948 discrim loss: 0.695082 total loss: 0.831948[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 83.0%, Avg loss: 0.575779 \n","\n","Epoch 2\n","------------------\n","## Meter  ## classification loss: 0.487271 discrim loss: 0.696588 total loss: 0.165366[    0/ 1601]\n","## Meter  ## classification loss: 0.192116 discrim loss: 0.695409 total loss: -0.129245[  640/ 1601]\n","## Meter  ## classification loss: 0.479213 discrim loss: 0.694410 total loss: 0.158314[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 87.7%, Avg loss: 0.391316 \n","\n","Epoch 3\n","------------------\n","## Meter  ## classification loss: 0.334134 discrim loss: 0.694381 total loss: -0.194703[    0/ 1601]\n","## Meter  ## classification loss: 0.153935 discrim loss: 0.694555 total loss: -0.375034[  640/ 1601]\n","## Meter  ## classification loss: 0.109871 discrim loss: 0.694750 total loss: -0.419246[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 91.0%, Avg loss: 0.267520 \n","\n","Epoch 4\n","------------------\n","## Meter  ## classification loss: 0.137387 discrim loss: 0.694801 total loss: -0.491511[    0/ 1601]\n","## Meter  ## classification loss: 0.111766 discrim loss: 0.695548 total loss: -0.517808[  640/ 1601]\n","## Meter  ## classification loss: 0.066430 discrim loss: 0.694921 total loss: -0.562577[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 92.0%, Avg loss: 0.231313 \n","\n","Epoch 5\n","------------------\n","## Meter  ## classification loss: 0.045094 discrim loss: 0.694814 total loss: -0.624726[    0/ 1601]\n","## Meter  ## classification loss: 0.080225 discrim loss: 0.694604 total loss: -0.589392[  640/ 1601]\n","## Meter  ## classification loss: 0.064948 discrim loss: 0.694654 total loss: -0.604717[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 92.5%, Avg loss: 0.247494 \n","\n","Epoch 6\n","------------------\n","## Meter  ## classification loss: 0.070863 discrim loss: 0.695246 total loss: -0.615076[    0/ 1601]\n","## Meter  ## classification loss: 0.092652 discrim loss: 0.694965 total loss: -0.593010[  640/ 1601]\n","## Meter  ## classification loss: 0.084478 discrim loss: 0.694846 total loss: -0.601067[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 91.7%, Avg loss: 0.261262 \n","\n","Epoch 7\n","------------------\n","## Meter  ## classification loss: 0.031258 discrim loss: 0.694652 total loss: -0.659959[    0/ 1601]\n","## Meter  ## classification loss: 0.035136 discrim loss: 0.694437 total loss: -0.655866[  640/ 1601]\n","## Meter  ## classification loss: 0.060133 discrim loss: 0.694995 total loss: -0.631425[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 93.7%, Avg loss: 0.191177 \n","\n","Epoch 8\n","------------------\n","## Meter  ## classification loss: 0.021996 discrim loss: 0.694658 total loss: -0.671396[    0/ 1601]\n","## Meter  ## classification loss: 0.031268 discrim loss: 0.694272 total loss: -0.661739[  640/ 1601]\n","## Meter  ## classification loss: 0.032359 discrim loss: 0.694692 total loss: -0.661067[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 92.7%, Avg loss: 0.246115 \n","\n","Epoch 9\n","------------------\n","## Meter  ## classification loss: 0.091462 discrim loss: 0.694639 total loss: -0.602711[    0/ 1601]\n","## Meter  ## classification loss: 0.071046 discrim loss: 0.694980 total loss: -0.623468[  640/ 1601]\n","## Meter  ## classification loss: 0.041719 discrim loss: 0.694623 total loss: -0.652438[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 93.0%, Avg loss: 0.194762 \n","\n","Epoch 10\n","------------------\n","## Meter  ## classification loss: 0.016060 discrim loss: 0.695287 total loss: -0.679056[    0/ 1601]\n","## Meter  ## classification loss: 0.020396 discrim loss: 0.694258 total loss: -0.673690[  640/ 1601]\n","## Meter  ## classification loss: 0.051979 discrim loss: 0.694790 total loss: -0.642639[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 91.0%, Avg loss: 0.272353 \n","\n","Done\n"]}],"source":["torch.autograd.set_detect_anomaly(True)\n","adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"]},{"cell_type":"markdown","source":["#### 5.1.2 Testing on Real Life"],"metadata":{"id":"1s0Z_xXXq5gO"},"id":"1s0Z_xXXq5gO"},{"cell_type":"code","execution_count":40,"id":"oUUo7mSiJasc","metadata":{"id":"oUUo7mSiJasc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9925592f-9402-4939-8f74-87209ef6c450","executionInfo":{"status":"ok","timestamp":1660120124335,"user_tz":-120,"elapsed":66358,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 62.5%, Avg loss: 1.264015 \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(1.264014733955264, 0.625)"]},"metadata":{},"execution_count":40}],"source":["loader_target_dataset = DataLoader(real_life_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","test_loop(loader_target_dataset, adv_model, device)"]},{"cell_type":"markdown","id":"FNofveL_-8gX","metadata":{"id":"FNofveL_-8gX"},"source":["### 5.2 Real Life -> Product"]},{"cell_type":"markdown","source":["#### 5.2.1 Training on Real Life"],"metadata":{"id":"6YxXx0Lzresh"},"id":"6YxXx0Lzresh"},{"cell_type":"code","source":["del adv_model"],"metadata":{"id":"b8MUwY3CFb6m","executionInfo":{"status":"ok","timestamp":1660120124336,"user_tz":-120,"elapsed":25,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"b8MUwY3CFb6m","execution_count":41,"outputs":[]},{"cell_type":"code","execution_count":42,"id":"enMKc_Em_tWq","metadata":{"id":"enMKc_Em_tWq","executionInfo":{"status":"ok","timestamp":1660120124336,"user_tz":-120,"elapsed":24,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["train_dataloader, train_test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])\n","target_dataloader, target_test_dataloader = get_dataloader(product_dataset, config['batch_size'])"]},{"cell_type":"code","execution_count":43,"id":"Msifip2P-7UB","metadata":{"id":"Msifip2P-7UB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"157f9272-82be-4dfa-e293-52a5d594fb1c","executionInfo":{"status":"ok","timestamp":1660121155423,"user_tz":-120,"elapsed":1031111,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","------------------\n","## Meter  ## classification loss: 3.008960 discrim loss: 0.702276 total loss: 3.008960[    0/ 1601]\n","## Meter  ## classification loss: 2.760247 discrim loss: 0.696447 total loss: 2.760247[  640/ 1601]\n","## Meter  ## classification loss: 2.114810 discrim loss: 0.694701 total loss: 2.114810[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 68.4%, Avg loss: 1.152067 \n","\n","Epoch 2\n","------------------\n","## Meter  ## classification loss: 0.946318 discrim loss: 0.695270 total loss: 0.625022[    0/ 1601]\n","## Meter  ## classification loss: 0.764657 discrim loss: 0.696100 total loss: 0.442977[  640/ 1601]\n","## Meter  ## classification loss: 0.667452 discrim loss: 0.695120 total loss: 0.346225[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 74.4%, Avg loss: 0.799938 \n","\n","Epoch 3\n","------------------\n","## Meter  ## classification loss: 0.548629 discrim loss: 0.695192 total loss: 0.019175[    0/ 1601]\n","## Meter  ## classification loss: 0.486324 discrim loss: 0.695851 total loss: -0.043632[  640/ 1601]\n","## Meter  ## classification loss: 0.395226 discrim loss: 0.695271 total loss: -0.134289[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 75.4%, Avg loss: 0.712332 \n","\n","Epoch 4\n","------------------\n","## Meter  ## classification loss: 0.293516 discrim loss: 0.695958 total loss: -0.336429[    0/ 1601]\n","## Meter  ## classification loss: 0.323229 discrim loss: 0.695095 total loss: -0.305935[  640/ 1601]\n","## Meter  ## classification loss: 0.422744 discrim loss: 0.695818 total loss: -0.207074[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 76.4%, Avg loss: 0.659406 \n","\n","Epoch 5\n","------------------\n","## Meter  ## classification loss: 0.221904 discrim loss: 0.695078 total loss: -0.448170[    0/ 1601]\n","## Meter  ## classification loss: 0.234723 discrim loss: 0.695447 total loss: -0.435708[  640/ 1601]\n","## Meter  ## classification loss: 0.195203 discrim loss: 0.695679 total loss: -0.475451[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 74.7%, Avg loss: 0.779258 \n","\n","Epoch 6\n","------------------\n","## Meter  ## classification loss: 0.298470 discrim loss: 0.695619 total loss: -0.387838[    0/ 1601]\n","## Meter  ## classification loss: 0.176382 discrim loss: 0.696286 total loss: -0.510583[  640/ 1601]\n","## Meter  ## classification loss: 0.246155 discrim loss: 0.695493 total loss: -0.440029[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 79.9%, Avg loss: 0.655613 \n","\n","Epoch 7\n","------------------\n","## Meter  ## classification loss: 0.112394 discrim loss: 0.695320 total loss: -0.579487[    0/ 1601]\n","## Meter  ## classification loss: 0.239538 discrim loss: 0.695260 total loss: -0.452284[  640/ 1601]\n","## Meter  ## classification loss: 0.150625 discrim loss: 0.695529 total loss: -0.541465[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 77.4%, Avg loss: 0.708837 \n","\n","Epoch 8\n","------------------\n","## Meter  ## classification loss: 0.122264 discrim loss: 0.695589 total loss: -0.572058[    0/ 1601]\n","## Meter  ## classification loss: 0.163890 discrim loss: 0.695356 total loss: -0.530199[  640/ 1601]\n","## Meter  ## classification loss: 0.219972 discrim loss: 0.694942 total loss: -0.473704[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 78.9%, Avg loss: 0.737204 \n","\n","Epoch 9\n","------------------\n","## Meter  ## classification loss: 0.129060 discrim loss: 0.695043 total loss: -0.565516[    0/ 1601]\n","## Meter  ## classification loss: 0.068486 discrim loss: 0.695254 total loss: -0.626301[  640/ 1601]\n","## Meter  ## classification loss: 0.108282 discrim loss: 0.696646 total loss: -0.587897[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 77.2%, Avg loss: 0.730387 \n","\n","Epoch 10\n","------------------\n","## Meter  ## classification loss: 0.085809 discrim loss: 0.695598 total loss: -0.609617[    0/ 1601]\n","## Meter  ## classification loss: 0.084517 discrim loss: 0.695570 total loss: -0.610882[  640/ 1601]\n","## Meter  ## classification loss: 0.070383 discrim loss: 0.694863 total loss: -0.624308[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 77.2%, Avg loss: 0.740960 \n","\n","Done\n"]}],"source":["# Training\n","adv_model = DANN(len(product_dataset.classes)).to(device)\n","adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"]},{"cell_type":"markdown","id":"nSh7gaC8JaVC","metadata":{"id":"nSh7gaC8JaVC"},"source":["#### 5.2.2 Testing on Product"]},{"cell_type":"code","execution_count":44,"id":"DfSRjr84-8DF","metadata":{"id":"DfSRjr84-8DF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6115e4e5-309c-4d32-f816-2e717d490902","executionInfo":{"status":"ok","timestamp":1660121193417,"user_tz":-120,"elapsed":38008,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 79.9%, Avg loss: 0.693335 \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.6933353942586109, 0.799)"]},"metadata":{},"execution_count":44}],"source":["loader_target_dataset = DataLoader(product_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","test_loop(loader_target_dataset, adv_model, device)"]},{"cell_type":"code","execution_count":45,"id":"bFtADV4AtN1Z","metadata":{"id":"bFtADV4AtN1Z","executionInfo":{"status":"ok","timestamp":1660121193418,"user_tz":-120,"elapsed":24,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"outputs":[],"source":["# del source_dataset, train_dataloader, test_dataloader, target_dataset, loader_target_dataset\n","del adv_model"]},{"cell_type":"markdown","source":["## 6 UDA Ablation Study"],"metadata":{"id":"aEOlulqbpt9j"},"id":"aEOlulqbpt9j"},{"cell_type":"markdown","source":["### 6.1 How Different Loss Functions Work"],"metadata":{"id":"SPbGilurqHN8"},"id":"SPbGilurqHN8"},{"cell_type":"markdown","source":["### 6.2 How UDA over different levels of feature layer work"],"metadata":{"id":"2iF-R_1nqn65"},"id":"2iF-R_1nqn65"},{"cell_type":"code","source":["# To test the middle layer feature adversarial training, we copy the model from torchvision and modify it.\n","class AlexNet(nn.Module):\n","    def __init__(self, num_classes: int = 1000, dropout: float = 0.5) -> None:\n","        super().__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )# 12544 = (6*6*256)\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(p=dropout),\n","            nn.Linear(256 * 6 * 6, 4096), \n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=dropout),\n","            nn.Linear(4096, 4096),  # original 4096\n","            nn.ReLU(inplace=True),\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        feature = self.features(x)\n","        x = self.avgpool(feature)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        feature = feature.view(feature.size(0), -1)\n","        # return x, x\n","        return x, feature"],"metadata":{"id":"PWbv3xDqqvde","executionInfo":{"status":"ok","timestamp":1660121479253,"user_tz":-120,"elapsed":432,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"PWbv3xDqqvde","execution_count":47,"outputs":[]},{"cell_type":"code","source":["class FeatureExtractor(nn.Module):\n","  def __init__(self, pretrained=True):\n","    super(FeatureExtractor, self).__init__()\n","    state_dict = alexnet(pretrained=pretrained).state_dict()\n","    self.feature_extractor = AlexNet()\n","    self.feature_extractor.load_state_dict(state_dict)\n","    self.feature_dim = self.feature_extractor.classifier[-1].in_features\n","    self.adv_feature_dim = 12544\n","    print(self.feature_dim, self.adv_feature_dim)\n","    # print(f\"Feature dimension: {self.feature_dim}\")\n","    # make the last layer identity\n","    self.feature_extractor.classifier[-1] = nn.Identity()\n","\n","  def forward(self, x):\n","    out = self.feature_extractor(x)\n","    return out\n","  \n","  def output_dim(self):\n","    return self.feature_dim\n","  \n","  def adv_output_dim(self):\n","    return self.adv_feature_dim"],"metadata":{"id":"rweuEqk5q4SQ","executionInfo":{"status":"ok","timestamp":1660121486857,"user_tz":-120,"elapsed":644,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"rweuEqk5q4SQ","execution_count":48,"outputs":[]},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self, input_dim):\n","        super(Discriminator, self).__init__()\n","        self.discriminator =  nn.Sequential(\n","            nn.Linear(int(input_dim), 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(1024,1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        validity = self.discriminator(x)\n","        return validity "],"metadata":{"id":"qK6zC5dqq6gn","executionInfo":{"status":"ok","timestamp":1660121491019,"user_tz":-120,"elapsed":3,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"qK6zC5dqq6gn","execution_count":49,"outputs":[]},{"cell_type":"code","source":["class DANN(nn.Module):\n","  # def __init__(self, num_classes, adversarial=True):\n","  def __init__(self, num_classes, pretrained=True):\n","    super(DANN, self).__init__()\n","    self.output_dim = num_classes\n","\n","    # define inner network component\n","    self.feature_extractor = FeatureExtractor(pretrained=pretrained)\n","    self.classifier = Classifier(self.feature_extractor.output_dim(), num_classes)\n","    self.discriminator = Discriminator(self.feature_extractor.adv_output_dim())  \n","  \n","  def forward(self, x):\n","    # 4096, 12544\n","    feature_output, adv_feature = self.feature_extractor(x)\n","    \n","    class_pred = self.classifier(feature_output)\n","\n","    # Add a ReverseLayer here for negative gradient computation\n","    reverse_feature = ReverseLayerF.apply(adv_feature)\n","    domain_pred = self.discriminator(reverse_feature)\n","\n","    return class_pred, domain_pred "],"metadata":{"id":"xiUoe6xTsGFw","executionInfo":{"status":"ok","timestamp":1660121491021,"user_tz":-120,"elapsed":5,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}}},"id":"xiUoe6xTsGFw","execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["Product -> Real Life"],"metadata":{"id":"In6J1hwisLeA"},"id":"In6J1hwisLeA"},{"cell_type":"code","source":["train_dataloader, train_test_dataloader = get_dataloader(product_dataset, config['batch_size'])\n","target_dataloader, target_test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])\n","adv_model = DANN(len(product_dataset.classes), pretrained=True).to(device)\n","torch.autograd.set_detect_anomaly(True)\n","adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h241WFL4sG-x","executionInfo":{"status":"ok","timestamp":1660122464968,"user_tz":-120,"elapsed":972057,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}},"outputId":"06b454f2-55b7-4d5b-f828-dfddc47a7a25"},"id":"h241WFL4sG-x","execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["4096 12544\n","Epoch 1\n","------------------\n","## Meter  ## classification loss: 3.007089 discrim loss: 0.703104 total loss: 3.007089[    0/ 1601]\n","## Meter  ## classification loss: 2.242389 discrim loss: 0.698007 total loss: 2.242389[  640/ 1601]\n","## Meter  ## classification loss: 0.674071 discrim loss: 0.696746 total loss: 0.674071[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 82.5%, Avg loss: 0.701569 \n","\n","Epoch 2\n","------------------\n","## Meter  ## classification loss: 0.737465 discrim loss: 0.697060 total loss: 0.415342[    0/ 1601]\n","## Meter  ## classification loss: 0.268852 discrim loss: 0.695527 total loss: -0.052563[  640/ 1601]\n","## Meter  ## classification loss: 0.298298 discrim loss: 0.695144 total loss: -0.022940[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 87.0%, Avg loss: 0.544255 \n","\n","Epoch 3\n","------------------\n","## Meter  ## classification loss: 0.321255 discrim loss: 0.694437 total loss: -0.207624[    0/ 1601]\n","## Meter  ## classification loss: 0.227817 discrim loss: 0.694351 total loss: -0.300997[  640/ 1601]\n","## Meter  ## classification loss: 0.158049 discrim loss: 0.694405 total loss: -0.370807[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 88.5%, Avg loss: 0.497565 \n","\n","Epoch 4\n","------------------\n","## Meter  ## classification loss: 0.118196 discrim loss: 0.693985 total loss: -0.509964[    0/ 1601]\n","## Meter  ## classification loss: 0.091960 discrim loss: 0.694182 total loss: -0.536378[  640/ 1601]\n","## Meter  ## classification loss: 0.169687 discrim loss: 0.694225 total loss: -0.458689[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 90.7%, Avg loss: 0.406460 \n","\n","Epoch 5\n","------------------\n","## Meter  ## classification loss: 0.071768 discrim loss: 0.694084 total loss: -0.597349[    0/ 1601]\n","## Meter  ## classification loss: 0.056916 discrim loss: 0.694091 total loss: -0.612206[  640/ 1601]\n","## Meter  ## classification loss: 0.082684 discrim loss: 0.694124 total loss: -0.586470[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 90.0%, Avg loss: 0.457307 \n","\n","Epoch 6\n","------------------\n","## Meter  ## classification loss: 0.055353 discrim loss: 0.693688 total loss: -0.629049[    0/ 1601]\n","## Meter  ## classification loss: 0.040419 discrim loss: 0.693884 total loss: -0.644177[  640/ 1601]\n","## Meter  ## classification loss: 0.130305 discrim loss: 0.693928 total loss: -0.554335[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 90.0%, Avg loss: 0.474108 \n","\n","Epoch 7\n","------------------\n","## Meter  ## classification loss: 0.059002 discrim loss: 0.693714 total loss: -0.631281[    0/ 1601]\n","## Meter  ## classification loss: 0.042482 discrim loss: 0.693803 total loss: -0.647890[  640/ 1601]\n","## Meter  ## classification loss: 0.076142 discrim loss: 0.693840 total loss: -0.614267[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 89.5%, Avg loss: 0.445268 \n","\n","Epoch 8\n","------------------\n","## Meter  ## classification loss: 0.034039 discrim loss: 0.693618 total loss: -0.658315[    0/ 1601]\n","## Meter  ## classification loss: 0.015950 discrim loss: 0.693711 total loss: -0.676496[  640/ 1601]\n","## Meter  ## classification loss: 0.032258 discrim loss: 0.693735 total loss: -0.660213[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 91.7%, Avg loss: 0.367910 \n","\n","Epoch 9\n","------------------\n","## Meter  ## classification loss: 0.047807 discrim loss: 0.693864 total loss: -0.645591[    0/ 1601]\n","## Meter  ## classification loss: 0.046527 discrim loss: 0.693840 total loss: -0.646847[  640/ 1601]\n","## Meter  ## classification loss: 0.038225 discrim loss: 0.693639 total loss: -0.654949[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 91.5%, Avg loss: 0.365072 \n","\n","Epoch 10\n","------------------\n","## Meter  ## classification loss: 0.033395 discrim loss: 0.693635 total loss: -0.660070[    0/ 1601]\n","## Meter  ## classification loss: 0.047758 discrim loss: 0.693768 total loss: -0.645839[  640/ 1601]\n","## Meter  ## classification loss: 0.045165 discrim loss: 0.693631 total loss: -0.648295[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 89.2%, Avg loss: 0.503952 \n","\n","Done\n"]}]},{"cell_type":"code","source":["loader_target_dataset = DataLoader(real_life_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","test_loop(loader_target_dataset, adv_model, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNeup5dEsR0h","executionInfo":{"status":"ok","timestamp":1660122532655,"user_tz":-120,"elapsed":67725,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}},"outputId":"4aec5d68-ef4f-442c-8a8e-ffdba0b4dd72"},"id":"vNeup5dEsR0h","execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 63.8%, Avg loss: 1.271149 \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(1.2711493540555239, 0.6385)"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["Real Life -> Product"],"metadata":{"id":"m_tpI5adsUBs"},"id":"m_tpI5adsUBs"},{"cell_type":"code","source":["config = dict(epochs=10, batch_size=64, lr=0.01, wd=0.001, momentum=0.9, alpha=10, beta=0.75, gamma=10)\n","train_dataloader, train_test_dataloader = get_dataloader(real_life_dataset, config['batch_size'])\n","target_dataloader, target_test_dataloader = get_dataloader(product_dataset, config['batch_size'])\n","adv_model = DANN(len(real_life_dataset.classes), pretrained=True).to(device)\n","torch.autograd.set_detect_anomaly(True)\n","adversarial_training(adv_model, train_dataloader, train_test_dataloader, target_dataloader, config, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fWAcM4ADsUXD","executionInfo":{"status":"ok","timestamp":1660123562262,"user_tz":-120,"elapsed":1029655,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}},"outputId":"804a9651-f73a-4dd8-d037-aa7dc7b3a2aa"},"id":"fWAcM4ADsUXD","execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["4096 12544\n","Epoch 1\n","------------------\n","## Meter  ## classification loss: 2.998693 discrim loss: 0.724238 total loss: 2.998693[    0/ 1601]\n","## Meter  ## classification loss: 2.731299 discrim loss: 0.710308 total loss: 2.731299[  640/ 1601]\n","## Meter  ## classification loss: 1.763867 discrim loss: 0.695495 total loss: 1.763867[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 66.4%, Avg loss: 1.300384 \n","\n","Epoch 2\n","------------------\n","## Meter  ## classification loss: 0.989391 discrim loss: 0.697166 total loss: 0.667219[    0/ 1601]\n","## Meter  ## classification loss: 0.933943 discrim loss: 0.694500 total loss: 0.613003[  640/ 1601]\n","## Meter  ## classification loss: 1.072262 discrim loss: 0.695066 total loss: 0.751060[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 74.2%, Avg loss: 0.829410 \n","\n","Epoch 3\n","------------------\n","## Meter  ## classification loss: 0.645482 discrim loss: 0.694187 total loss: 0.116793[    0/ 1601]\n","## Meter  ## classification loss: 0.559664 discrim loss: 0.694190 total loss: 0.030973[  640/ 1601]\n","## Meter  ## classification loss: 0.793196 discrim loss: 0.694408 total loss: 0.264339[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 73.9%, Avg loss: 0.820846 \n","\n","Epoch 4\n","------------------\n","## Meter  ## classification loss: 0.471663 discrim loss: 0.693869 total loss: -0.156391[    0/ 1601]\n","## Meter  ## classification loss: 0.507609 discrim loss: 0.694120 total loss: -0.120673[  640/ 1601]\n","## Meter  ## classification loss: 0.258847 discrim loss: 0.693945 total loss: -0.369277[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 73.4%, Avg loss: 0.783826 \n","\n","Epoch 5\n","------------------\n","## Meter  ## classification loss: 0.334834 discrim loss: 0.693732 total loss: -0.333943[    0/ 1601]\n","## Meter  ## classification loss: 0.127460 discrim loss: 0.693862 total loss: -0.541442[  640/ 1601]\n","## Meter  ## classification loss: 0.249523 discrim loss: 0.693846 total loss: -0.419363[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 76.7%, Avg loss: 0.731583 \n","\n","Epoch 6\n","------------------\n","## Meter  ## classification loss: 0.234664 discrim loss: 0.693780 total loss: -0.449829[    0/ 1601]\n","## Meter  ## classification loss: 0.213042 discrim loss: 0.693742 total loss: -0.471414[  640/ 1601]\n","## Meter  ## classification loss: 0.210370 discrim loss: 0.693866 total loss: -0.474208[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 74.9%, Avg loss: 0.733879 \n","\n","Epoch 7\n","------------------\n","## Meter  ## classification loss: 0.113531 discrim loss: 0.693810 total loss: -0.576848[    0/ 1601]\n","## Meter  ## classification loss: 0.106569 discrim loss: 0.693918 total loss: -0.583917[  640/ 1601]\n","## Meter  ## classification loss: 0.200041 discrim loss: 0.693889 total loss: -0.490417[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 78.2%, Avg loss: 0.827372 \n","\n","Epoch 8\n","------------------\n","## Meter  ## classification loss: 0.103474 discrim loss: 0.693810 total loss: -0.589072[    0/ 1601]\n","## Meter  ## classification loss: 0.092648 discrim loss: 0.693642 total loss: -0.599730[  640/ 1601]\n","## Meter  ## classification loss: 0.169832 discrim loss: 0.693741 total loss: -0.522645[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 77.7%, Avg loss: 0.731297 \n","\n","Epoch 9\n","------------------\n","## Meter  ## classification loss: 0.101014 discrim loss: 0.693744 total loss: -0.592265[    0/ 1601]\n","## Meter  ## classification loss: 0.132239 discrim loss: 0.693818 total loss: -0.561113[  640/ 1601]\n","## Meter  ## classification loss: 0.078448 discrim loss: 0.693691 total loss: -0.614777[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 78.4%, Avg loss: 0.851487 \n","\n","Epoch 10\n","------------------\n","## Meter  ## classification loss: 0.100346 discrim loss: 0.693588 total loss: -0.593071[    0/ 1601]\n","## Meter  ## classification loss: 0.117111 discrim loss: 0.693699 total loss: -0.576418[  640/ 1601]\n","## Meter  ## classification loss: 0.101014 discrim loss: 0.693664 total loss: -0.592479[ 1280/ 1601]\n","Source Test Test Error: \n"," Accuracy: 79.4%, Avg loss: 0.804330 \n","\n","Done\n"]}]},{"cell_type":"code","source":["loader_target_dataset = DataLoader(product_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","test_loop(loader_target_dataset, adv_model, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcDXQ9TysUmn","executionInfo":{"status":"ok","timestamp":1660123601457,"user_tz":-120,"elapsed":39209,"user":{"displayName":"Tianyu Xu","userId":"02171164844935640871"}},"outputId":"55f93ae4-91a2-4287-b474-b010b0f337b9"},"id":"qcDXQ9TysUmn","execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Error: \n"," Accuracy: 79.6%, Avg loss: 0.696960 \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.6969601637683809, 0.796)"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["## 7 Summary"],"metadata":{"id":"jA4CUBAtqYXB"},"id":"jA4CUBAtqYXB"},{"cell_type":"markdown","source":["### 6.1 Product -> Real Life\n"],"metadata":{"id":"S41pMBv6uy9b"},"id":"S41pMBv6uy9b"},{"cell_type":"markdown","source":["#### 6.1.1 Purely training on Source Domain-Product\n","\n","Without using any domain adaptation techniques, within 10 epochs training, the classifier network achieves  64.6% accuracy on the target domain."],"metadata":{"id":"bkflD8rau94r"},"id":"bkflD8rau94r"},{"cell_type":"markdown","source":["#### 6.1.2 Training on both Source and Target Domains\n","\n","Using DANN doamin adaptation technique, the classifier with feature extractor trained on both source and target domain achives 64.6% accuracy, which is the same as the one trained solely on the source domain, with no improvement on accuracy."],"metadata":{"id":"vxoGKmCJvHqD"},"id":"vxoGKmCJvHqD"},{"cell_type":"markdown","source":["### 6.2 Real Life -> Product"],"metadata":{"id":"QTVdi9zvuysa"},"id":"QTVdi9zvuysa"},{"cell_type":"markdown","source":["#### 6.2.1 Purely Training on Source Domain-Real Life\n","\n","The classifier trained solely on the source domain achives 79.2% accuracy on the target domain."],"metadata":{"id":"_rV09wirvMcM"},"id":"_rV09wirvMcM"},{"cell_type":"markdown","source":["#### 6.2.2 Training on both Source and Target Domains\n","\n","With feature extractor trained on both source and target domain, the classifer achives 91.9% accuracy on the target domain, which is about 12% improvement over feature extractor purely trained on source domain."],"metadata":{"id":"VShk9r-GvM2U"},"id":"VShk9r-GvM2U"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"UDA_GAN.ipynb","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"26281c309c5b44cb8a192b66deccbdec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a8c973d3e34044f08090d19372fb8dff","IPY_MODEL_786a38756c47432fa545b3e868bda1e3","IPY_MODEL_ee51668878e048989dbd6e0f76e8f655"],"layout":"IPY_MODEL_3aa4cb67fc954f9991499332337e9712"}},"a8c973d3e34044f08090d19372fb8dff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_860230e73f55419183849201358e6835","placeholder":"​","style":"IPY_MODEL_16c63f18a2b343168b076a9009f3bb9c","value":"100%"}},"786a38756c47432fa545b3e868bda1e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de62612dff164f178dc01fb8d48f67b5","max":244408911,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3aaeb2426e114af5b3f3ef8bbdedf424","value":244408911}},"ee51668878e048989dbd6e0f76e8f655":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f6bea95a3f242dca83d8925b75ea2b8","placeholder":"​","style":"IPY_MODEL_ccaaf8bbcda44268b099d4ff66fc173b","value":" 233M/233M [00:00&lt;00:00, 325MB/s]"}},"3aa4cb67fc954f9991499332337e9712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860230e73f55419183849201358e6835":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16c63f18a2b343168b076a9009f3bb9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de62612dff164f178dc01fb8d48f67b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aaeb2426e114af5b3f3ef8bbdedf424":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f6bea95a3f242dca83d8925b75ea2b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccaaf8bbcda44268b099d4ff66fc173b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}